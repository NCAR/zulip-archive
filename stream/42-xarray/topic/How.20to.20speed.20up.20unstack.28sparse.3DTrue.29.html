<html>
<head><meta charset="utf-8"><title>How to speed up unstack(sparse=True) · xarray · Zulip Chat Archive</title></head>
<h2>Stream: <a href="http://127.0.0.1:4000/html/stream/42-xarray/index.html">xarray</a></h2>
<h3>Topic: <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html">How to speed up unstack(sparse=True)</a></h3>

<hr>

<base href="https://zulip2.cloud.ucar.edu">

<head><link href="http://127.0.0.1:4000/style.css" rel="stylesheet"></head>

<a name="36229"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36229" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36229">(Jul 01 2021 at 21:27)</a>:</h4>
<p>I have a large pandas MultiIndex (800,000 rows) that is taking a long time to unstack to sparse form.</p>
<div class="codehilite"><pre><span></span>### Preprocessing Steps for each input dataset before merge
def preprocess(ds):
    &quot;&quot;&quot;Pare down each input dataset to a single variable.
       The subsequent merge will eliminate unused coordinates automatically.

        This function does not allow additional arguments, so the target
        output variable needs to be defined globally in TARGET_VAR.
    &quot;&quot;&quot;
    drop_vars = [var for var in ds.data_vars
                 if var != TARGET_VAR]

    ds_fixed = ds.drop_vars(drop_vars)

    lats = list(ds.pfts1d_lat.astype(&#39;float32&#39;).data)
    lons = list(ds.pfts1d_lon.astype(&#39;float32&#39;).data)
    vegtype = list(ds.pfts1d_itype_veg.data)
    coltype = list(ds.pfts1d_itype_col.data)
    lunittype = list(ds.pfts1d_itype_lunit.data)
    active = list(ds.pfts1d_active.data)

    # Redefine the &#39;pft&#39; dimension as a multi-index, which will increase the number of dimensions.
    index = pd.MultiIndex.from_arrays([lats, lons, vegtype, coltype, lunittype, active],
                                  names=(&#39;pftlat&#39;, &#39;pftlon&#39;, &#39;vegtype&#39;, &#39;coltype&#39;, &#39;lunittype&#39;, &#39;active&#39;))
    ds_fixed[&#39;pft&#39;] = index


    # Keep the data sparse if possible to avoid memory shortages.
    ds_fixed = ds_fixed.unstack(sparse=True)
    return ds_fixed
</pre></div>


<p>Does anyone know if there is a way to speed up unstack() with Dask?</p>



<a name="36230"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36230" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36230">(Jul 01 2021 at 21:37)</a>:</h4>
<p>I should add that the source data comes from a Zarr store where I tried to chunk the 'pft' dimension (the one being unstacked) into chunks of 10,000 elements each.   I don't know if this helps or hurts.</p>



<a name="36231"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36231" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Deepak Cherian <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36231">(Jul 01 2021 at 21:39)</a>:</h4>
<p>No. the fast way requires "advanced indexing" over multiple dimensions which is not supported by both dask and sparse. See discussion here: <a href="https://github.com/pydata/xarray/blob/c472f8a4c79f872edb9dcd7825f786ecb9aff5c0/xarray/core/dataset.py#L4129-L4152" target="_blank" title="https://github.com/pydata/xarray/blob/c472f8a4c79f872edb9dcd7825f786ecb9aff5c0/xarray/core/dataset.py#L4129-L4152">https://github.com/pydata/xarray/blob/c472f8a4c79f872edb9dcd7825f786ecb9aff5c0/xarray/core/dataset.py#L4129-L4152</a></p>



<a name="36232"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36232" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36232">(Jul 01 2021 at 21:40)</a>:</h4>
<p>Thanks for that info!  Much appreciated.</p>



<a name="36233"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36233" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36233">(Jul 01 2021 at 21:48)</a>:</h4>
<p>One more related question: is it possible that chunking the "pft" dimension ahead of time just creates extra work for the unstack() operation?</p>



<a name="36236"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36236" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Deepak Cherian <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36236">(Jul 01 2021 at 21:52)</a>:</h4>
<p>yes it's forced to take the slow path. You'll want to call <code>unstack</code> on a numpy-backed Xarray thing for max speed. You could use <code>xarray.map_blocks</code> for this as long as you're not chunked along <code>pft</code> You'll also want to pass only variables required by <code>preprocess</code> to the <code>map_blocks</code> call.</p>



<a name="36312"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36312" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36312">(Jul 02 2021 at 13:09)</a>:</h4>
<p>Hi Deepak, </p>
<p>I just want to make sure I followed your advice properly, but it looks like the slow behavior is unchanged with the following code.   Did I do anything wrong here?</p>
<p>If there is any other way to produce sparse results that might be faster, I would be interested.   Otherwise, we may decide to wait on producing these variables for the cloud.   </p>
<div class="codehilite"><pre><span></span>def compute_index(ds):
    &quot;&quot;&quot;Compute the transform from 1D to sparse 6D
    &quot;&quot;&quot;
    lats = list(ds.pfts1d_lat.astype(&#39;float32&#39;).data)
    lons = list(ds.pfts1d_lon.astype(&#39;float32&#39;).data)
    vegtype = list(ds.pfts1d_itype_veg.data)
    coltype = list(ds.pfts1d_itype_col.data)
    lunittype = list(ds.pfts1d_itype_lunit.data)
    active = list(ds.pfts1d_active.data)

    # Redefine the &#39;pft&#39; dimension as a multi-index, which will increase the number of dimensions.
    index = pd.MultiIndex.from_arrays([lats, lons, vegtype, coltype, lunittype, active],
                                  names=(&#39;pftlat&#39;, &#39;pftlon&#39;, &#39;vegtype&#39;, &#39;coltype&#39;, &#39;lunittype&#39;, &#39;active&#39;))

    return index

def sparsify(chunk):
    chunk = chunk.unstack(sparse=True)
    return chunk

def preprocess(ds):
    index = compute_index(ds)
    ds[&#39;pft&#39;] = index

    # Drop all but one PFT-related variable to make conversion faster
    drop_vars = [var for var in ds.data_vars
                 if var not in PFT_VARS]
    ds = ds.drop_vars(drop_vars)

    ds = ds.chunk(chunks={&quot;time&quot;: 100})

   # I also tried loading the data to see if it could reduce what looks like pulling small chunks from disk.
   #  ds = ds.load()
    ds_fixed = xr.map_blocks(sparsify, ds)

    return ds_fixed
</pre></div>



<a name="36324"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36324" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Deepak Cherian <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36324">(Jul 02 2021 at 15:51)</a>:</h4>
<p>I'm surprised you could do <code>map_blocks</code> without passing <code>template</code>. Does <code>ds_fixed</code> (before computing) look like what you expect? Is <code>compute_index</code> slow? Does it help to move <code>compute_index</code> in to the <code>sparsify</code> call?</p>



<a name="36329"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36329" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36329">(Jul 02 2021 at 16:16)</a>:</h4>
<p><code>compute_index()</code> takes 3-4 minutes.  It appears that the call to <code>unstack()</code> is taking a long time (more than 3 hours for a single variable).   The dask task graphs look like they are processing one timestep at a time, despite my efforts to chunk the dataset along the time dimension.   When 50 workers are present, each worker cpu is at around 10%, which suggests to me that 90% of the time is spent waiting for values to come from disk.  Of course, I'm not fully confident that I'm seeing things correctly.</p>



<a name="36330"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36330" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36330">(Jul 02 2021 at 16:18)</a>:</h4>
<p>I'm also not aware of how to check <code>ds_fixed</code>.   In the past when I tried putting in print statements in <code>preprocess()</code>, I was not getting anything printed.   Perhaps I should try again somehow?</p>



<a name="36331"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36331" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Deepak Cherian <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36331">(Jul 02 2021 at 16:19)</a>:</h4>
<p>If you want to put <code>print</code> statements, use <code>.compute(scheduler="single-threaded")</code> this will run it in serial. Otherwise, I think we should push this to the next office hours.</p>



<a name="36333"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36333" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36333">(Jul 02 2021 at 18:48)</a>:</h4>
<p>Another possible explanation for the 10% cpu per worker is that the <code>unstack()</code> operation is being done serially, over a huge MultiIndex, and even with chunking in time, it is always going to be slow going through the MultiIndex in a serial way.   </p>
<p>Perhaps <code>unstack()</code> would be much faster if we can pull the data into memory all at once?   I thought that <code>ds = ds.load()</code> just before the unstack would force this, but it doesn't seem to change the speed for <code>unstack()</code>.     Is this a possible issue to raise, or am I misunderstanding something?</p>



<a name="36336"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36336" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Deepak Cherian <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36336">(Jul 02 2021 at 19:02)</a>:</h4>
<p>When you wrap a function in <code>map_blocks</code> , at compute-time that function will receive an xarray object with data loaded into memory. so in theory it's using the fast-path for numpy objects.</p>
<p>You can test out the speed of unstacking by loading one timestep in to memory and profiling the <code>unstack</code> call.</p>



<a name="36338"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36338" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36338">(Jul 02 2021 at 20:23)</a>:</h4>
<p>After reducing to one timestep, I'm still getting the same dask pattern and speed.   Profile says that 96% of the time is spent in <code>compute_index()</code>.   Of that, 46% of the time is for <code>slice_array()</code> and the rest is for <code>factorize_for_iterables()</code>.   The code now looks like this, I hope I have done things correctly and the intent is obvious:</p>
<div class="codehilite"><pre><span></span>def preprocess(ds):
    TARGET_CHUNKS = {&#39;time&#39;: 10}
    PFT_VARS = [&#39;TLAI&#39;]

    index = compute_index(ds)
    ds[&#39;pft&#39;] = index

    # Drop unneeded variables as soon as possible.
    drop_vars = [var for var in ds.data_vars
                 if var not in PFT_VARS]
    ds = ds.drop_vars(drop_vars)

    ds = ds.load()

    ds = ds.chunk(chunks=TARGET_CHUNKS)

    for var in PFT_VARS:
        # Try limiting to one timestep.
        ds[var] = ds[var].isel(time=0)
        ds[var] = xr.map_blocks(sparsify, ds[var])

    return ds
</pre></div>



<a name="36339"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/42-xarray/topic/How%20to%20speed%20up%20unstack%28sparse%3DTrue%29/near/36339" class="zl"><img src="http://127.0.0.1:4000/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Brian Bonnlander <a href="http://127.0.0.1:4000/html/stream/42-xarray/topic/How.20to.20speed.20up.20unstack.28sparse.3DTrue.29.html#36339">(Jul 02 2021 at 20:28)</a>:</h4>
<p>I think the profile results suggest that unstack() is looping over the MultiIndex and processing one element (of 800,000) at a time in order.</p>



<hr><p>Last updated: Dec 17 2024 at 18:57 UTC</p>
</html>