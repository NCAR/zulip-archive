<html>
<head><meta charset="utf-8"><title>Datasets and Dataloaders · machine-learning · Zulip Chat Archive</title></head>
<div class='page-content'><h2>Stream: <a href="https://ncar.github.io/zulip-archive/stream/50-machine-learning/index.html">machine-learning</a></h2>
<h3>Topic: <a href="https://ncar.github.io/zulip-archive/stream/50-machine-learning/topic/Datasets.20and.20Dataloaders.html">Datasets and Dataloaders</a></h3>

<hr>

<base href="https://zulip2.cloud.ucar.edu/">

<head><link href="https://ncar.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="37007"></a>
<h4><a href="https://zulip2.cloud.ucar.edu/#narrow/stream/50-machine-learning/topic/Datasets%20and%20Dataloaders/near/37007" class="zl"><img src="https://ncar.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Maria Molina <a href="https://ncar.github.io/zulip-archive/stream/50-machine-learning/topic/Datasets.20and.20Dataloaders.html#37007">(Jul 12 2021 at 20:43)</a>:</h4>
<p>Here is a pytorch intro to datasets and dataloaders, which really help with some data preprocessing during training, but still doesn't resolve my main issue on how to normalize data based on varying data distributions <a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html" target="_blank" title="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">https://pytorch.org/tutorials/beginner/basics/data_tutorial.html</a></p>



<a name="37008"></a>
<h4><a href="https://zulip2.cloud.ucar.edu/#narrow/stream/50-machine-learning/topic/Datasets%20and%20Dataloaders/near/37008" class="zl"><img src="https://ncar.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Maria Molina <a href="https://ncar.github.io/zulip-archive/stream/50-machine-learning/topic/Datasets.20and.20Dataloaders.html#37008">(Jul 12 2021 at 20:47)</a>:</h4>
<p>Currently, I compute the min/max, mean, standard deviation, etc of each respective variable for each of the training sets prior to training, then use those values as input into the dataset/dataloader preprocessing</p>



<hr><p>Last updated: Jan 30 2022 at 12:01 UTC</p>
</html></div>