<html>
<head><meta charset="utf-8"><title>saving to zarr results in error · dask · Zulip Chat Archive</title></head>
<h2>Stream: <a href="../../..//stream/27-dask/index.html">dask</a></h2>
<h3>Topic: <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html">saving to zarr results in error</a></h3>

<hr>


<head><link href="../../../style.css" rel="stylesheet"></head>

<a name="49738"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49738" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49738">(Jan 26 2022 at 23:52)</a>:</h4>
<p>Hi,</p>
<p>I'm trying to save a dataArray to a zarr file, and have been able to do this in the past with similar code.  However, lately I've run into this issue which I cannot seem to resolve.</p>
<p>Say my DataArray looks like this: </p>
<p>aw_oceanT_global<br>
xarray.DataArraytime: 3600 z_t:  60<br>
                     Array  Chunk<br>
Bytes   1.65 MiB    480 B<br>
Shape   (3600, 60)  (1, 60)<br>
Count   154875 Tasks    3600 Chunks<br>
Type    float64 numpy.ndarray   </p>
<p>I do :</p>
<p>aw_oceanT_global.unify_chunks()<br>
aw_oceanT_global.to_dataset(name='TEMP').chunk({'z_t':-1}).to_zarr('/glade/scratch/mberdahl/127kaH11/TEMP/aw_oceanT_global_timeseries_H11.zarr', mode='w')</p>
<p>But receive the following error (just the top bit of it):<br>
distributed.utils - ERROR - 'str' object has no attribute 'text'<br>
Traceback (most recent call last):<br>
  File "/glade/work/mberdahl/miniconda/envs/pangeo/lib/python3.9/site-packages/distributed/utils.py", line 681, in log_errors<br>
    yield<br>
  File "/glade/work/mberdahl/miniconda/envs/pangeo/lib/python3.9/site-packages/distributed/dashboard/components/scheduler.py", line 346, in update<br>
    self.root.title.text = title<br>
AttributeError: 'str' object has no attribute 'text'<br>
distributed.utils - ERROR - 'str' object has no attribute 'text'<br>
Traceback (most recent call last):<br>
  File "/glade/work/mberdahl/miniconda/envs/pangeo/lib/python3.9/site-packages/distributed/utils.py", line 681, in log_errors<br>
    yield<br>
  File "/glade/work/mberdahl/miniconda/envs/pangeo/lib/python3.9/site-packages/distributed/dashboard/components/scheduler.py", line 3417, in status_doc<br>
    cluster_memory.update()</p>
<p>Looks like I'm running into memory issues maybe?bBut this DataArray isn't any bigger than other arrays I've had success with with the same methods.  Any thoughts appreciated!</p>



<a name="49741"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49741" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49741">(Jan 27 2022 at 00:25)</a>:</h4>
<p><span class="user-mention" data-user-id="259">@Mira Berdahl</span>, I don't know why this is failing by looking at the traceback. Can you provide a reproducible test case or a pointer to the notebook you're using?</p>



<a name="49743"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49743" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49743">(Jan 27 2022 at 02:51)</a>:</h4>
<p><span class="user-mention" data-user-id="13">@Anderson Banihirwe</span> , the path to the notebook is:<br>
/glade/u/home/mberdahl/FirstLook_LIGruns/DASK_scripts/TryAreaWeightingAvg.ipynb<br>
Thanks for taking a look!</p>



<a name="49839"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49839" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49839">(Jan 31 2022 at 17:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="259">Mira Berdahl</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49743">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> , the path to the notebook is:<br>
/glade/u/home/mberdahl/FirstLook_LIGruns/DASK_scripts/TryAreaWeightingAvg.ipynb<br>
Thanks for taking a look!</p>
</blockquote>
<p>Thanks, <span class="user-mention" data-user-id="259">@Mira Berdahl</span>! Unfortunately, I haven't been able to fix the issue (I am getting a <code>KilledWorkerError</code> when using the full dataset). In the meantime, I suggest trying the following:</p>
<p>1) Reduce the data size you're loading (e.g. load <code>1/4</code> of it)</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="n">mfds</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_mfdataset</span><span class="p">(</span><span class="n">dfiles</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">dfiles</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">],</span> <span class="n">combine</span><span class="o">=</span><span class="s1">'by_coords'</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">True</span> <span class="p">,</span> <span class="n">chunks</span><span class="o">=</span><span class="p">{</span><span class="s1">'time'</span><span class="p">:</span> <span class="mi">6</span><span class="p">},</span> <span class="n">data_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'TEMP'</span><span class="p">,</span> <span class="s1">'time_bound'</span><span class="p">],</span> <span class="n">decode_times</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p>2) Ensure the computations are done in single precision (<code>float32</code>) so as to avoid <strong>memory usage</strong> blowing up:</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="k">def</span> <span class="nf">weighted_temporal_mean</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="s1">'nlat'</span><span class="p">,</span> <span class="s1">'nlon'</span><span class="p">)):</span>
    <span class="sd">"""</span>
<span class="sd">    weight by days in each month</span>
<span class="sd">    """</span>
    <span class="c1">#time_bound_diff = ds.time_bnds.diff(dim="nbnds")[:, 0]</span>
    <span class="n">month_length</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days_in_month</span>
    <span class="n">wgts</span> <span class="o">=</span> <span class="p">(</span><span class="n">month_length</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"time.year"</span><span class="p">)</span> <span class="o">/</span> <span class="n">month_length</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"time.year"</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
    <span class="c1">#wgts = time_bound_diff.groupby("time.year") / time_bound_diff.groupby(</span>
    <span class="c1">#    "time.year"</span>
    <span class="c1">#).sum(xr.ALL_DIMS)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">wgts</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"time.year"</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">xr</span><span class="o">.</span><span class="n">ALL_DIMS</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
    <span class="n">obs_sum</span> <span class="o">=</span> <span class="p">(</span><span class="n">obs</span> <span class="o">*</span> <span class="n">wgts</span><span class="p">)</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="s2">"AS"</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">"time"</span><span class="p">)</span>
    <span class="n">ones_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">ones</span> <span class="o">*</span> <span class="n">wgts</span><span class="p">)</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="s2">"AS"</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s2">"time"</span><span class="p">)</span>
    <span class="c1">#obs_s = (obs_sum / ones_out).mean(dims).to_series()</span>
    <span class="k">return</span> <span class="n">obs_sum</span> <span class="o">/</span> <span class="n">ones_out</span>
</code></pre></div>
<p>Notice the <code>.astype('float32')</code>  in <code>weighted_temporal_mean</code> function and in the following line:</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="n">areacello</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">TAREA</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">KMT</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
</code></pre></div>
<p>3) The resultant dataset when computing the following is so tiny (~10MB) that I recommend avoiding the <code>re-chunking</code> and <code>loading</code> everything in memory before writing to disk (in <code>netCDF</code>)</p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="n">aw_oceanT_global</span> <span class="o">=</span> <span class="p">(</span><span class="n">Annual_oceanT_H11</span> <span class="o">*</span> <span class="n">areacello</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="s1">'nlat'</span><span class="p">,</span><span class="s1">'nlon'</span><span class="p">])</span><span class="o">/</span><span class="n">areacello</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">aw_oceanT_global</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">aw_oceanT_global</span><span class="o">.</span><span class="n">to_dataset</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'TEMP'</span><span class="p">)</span><span class="o">.</span><span class="n">to_netcdf</span><span class="p">(</span><span class="s2">"............"</span><span class="p">)</span>
</code></pre></div>



<a name="49842"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49842" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49842">(Jan 31 2022 at 17:34)</a>:</h4>
<p>I am planning to tinker with this later today to see if I can get it to work on the full dataset. I'll keep you posted...</p>



<a name="49940"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49940" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49940">(Feb 02 2022 at 22:24)</a>:</h4>
<p>Hi <span class="user-mention" data-user-id="13">@Anderson Banihirwe</span> <br>
Sorry for the delay on my end (childcare center closures have derailed me). Anyway, thanks for these suggestions. I'm able to get these methods to work while loading half the dataset. Any reason why you recommend saving as netcdf over zarr in this case?<br>
I'll look out for any other suggestions you have for getting this working for the full dataset.  Thanks!</p>



<a name="49942"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49942" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49942">(Feb 02 2022 at 22:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="259">Mira Berdahl</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49940">said</a>:</p>
<blockquote>
<p>Hi <span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> <br>
Sorry for the delay on my end (childcare center closures have derailed me). Anyway, thanks for these suggestions. I'm able to get these methods to work while loading half the dataset. Any reason why you recommend saving as netcdf over zarr in this case?<br>
I'll look out for any other suggestions you have for getting this working for the full dataset.  Thanks!</p>
</blockquote>
<p>Actually I take part of this back. I can get my notebook to work for half my dataset if I stick to saving to zarr.  The process of loading the area weighted mean and then saving to nc fails with a killedWorker error.  So seems like half is still too big for that method.</p>



<a name="49943"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49943" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49943">(Feb 02 2022 at 23:05)</a>:</h4>
<blockquote>
<p>Sorry for the delay on my end (childcare center closures have derailed me). Anyway, thanks for these suggestions.</p>
</blockquote>
<p>No worries...</p>
<blockquote>
<p>Actually I take part of this back. I can get my notebook to work for half my dataset if I stick to saving to zarr. The process of loading the area weighted mean and then saving to nc fails with a killedWorker error. So seems like half is still too big for that method.</p>
</blockquote>
<p>Interesting <span aria-label="thinking" class="emoji emoji-1f914" role="img" title="thinking">:thinking:</span>  So mysterious... Is your notebook still active? If so, could you send me the output of the following commands: </p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="kn">import</span> <span class="nn">dask</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"jobqueue.pbs.log-directory"</span><span class="p">))</span>
</code></pre></div>



<a name="49944"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49944" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49944">(Feb 02 2022 at 23:12)</a>:</h4>
<p>Sure thing, it gives back the following path:<br>
/glade/scratch/mberdahl/dask/casper-dav/logs</p>
<p>Also having issues with getting enough workers, I request 12, but only ever receive 4 despite waiting a few hrs...</p>



<a name="49945"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49945" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49945">(Feb 02 2022 at 23:15)</a>:</h4>
<blockquote>
<p>Also having issues with getting enough workers, I request 12, but only ever receive 4 despite waiting a few hrs...</p>
</blockquote>
<p>I believe this is a CASPER issue (not sure but it appears to have a bunch of pending jobs in the queue)</p>



<a name="49946"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49946" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49946">(Feb 02 2022 at 23:16)</a>:</h4>
<p>What's the output of </p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"distributed"</span><span class="p">))</span>
</code></pre></div>



<a name="49948"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49948" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49948">(Feb 02 2022 at 23:17)</a>:</h4>
<p><span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49946">said</a>:</p>
<blockquote>
<p>What's the output of </p>
<p><div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"distributed"</span><span class="p">))</span>
</code></pre></div><br>
</p>
</blockquote>
<p>This is what I see when I run that:<br>
{'scheduler': {'bandwidth': 1000000000, 'allowed-failures': 3, 'blocked-handlers': [], 'default-data-size': '1kiB', 'events-cleanup-delay': '1h', 'idle-timeout': None, 'transition-log-length': 100000, 'events-log-length': 100000, 'work-stealing': True, 'work-stealing-interval': '100ms', 'worker-ttl': None, 'pickle': True, 'preload': [], 'preload-argv': [], 'unknown-task-duration': '500ms', 'default-task-durations': {'rechunk-split': '1us', 'split-shuffle': '1us'}, 'validate': False, 'dashboard': {'status': {'task-stream-length': 1000}, 'tasks': {'task-stream-length': 100000}, 'tls': {'ca-file': None, 'key': None, 'cert': None}, 'bokeh-application': {'allow_websocket_origin': ['*'], 'keep_alive_milliseconds': 500, 'check_unused_sessions_milliseconds': 500}}, 'locks': {'lease-validation-interval': '10s', 'lease-timeout': '30s'}, 'http': {'routes': ['distributed.http.scheduler.prometheus', '<a href="http://distributed.http.scheduler.info">distributed.http.scheduler.info</a>', 'distributed.http.scheduler.json', '<a href="http://distributed.http.health">distributed.http.health</a>', 'distributed.http.proxy', 'distributed.http.statics']}, 'allowed-imports': ['dask', 'distributed'], 'active-memory-manager': {'start': False, 'interval': '2s', 'policies': [{'class': 'distributed.active_memory_manager.ReduceReplicas'}]}}, 'worker': {'memory': {'target': 0.9, 'spill': False, 'pause': 0.8, 'terminate': 0.95, 'recent-to-old-time': '30s', 'rebalance': {'measure': 'optimistic', 'sender-min': 0.3, 'recipient-max': 0.6, 'sender-recipient-gap': 0.1}}, 'blocked-handlers': [], 'multiprocessing-method': 'spawn', 'use-file-locking': True, 'connections': {'outgoing': 50, 'incoming': 10}, 'preload': [], 'preload-argv': [], 'daemon': True, 'validate': False, 'resources': {}, 'lifetime': {'duration': None, 'stagger': '0 seconds', 'restart': False}, 'profile': {'interval': '10ms', 'cycle': '1000ms', 'low-level': False}, 'http': {'routes': ['distributed.http.worker.prometheus', '<a href="http://distributed.http.health">distributed.http.health</a>', 'distributed.http.statics']}}, 'comm': {'compression': None, 'retry': {'count': 0, 'delay': {'min': '1s', 'max': '20s'}}, 'shard': '64MiB', 'offload': '10MiB', 'default-scheme': 'tcp', 'socket-backlog': 2048, 'recent-messages-log-length': 0, 'ucx': {'cuda-copy': None, 'tcp': None, 'nvlink': None, 'infiniband': None, 'rdmacm': None, 'net-devices': None, 'reuse-endpoints': None, 'create-cuda-context': None}, 'zstd': {'level': 3, 'threads': 0}, 'timeouts': {'connect': '30s', 'tcp': '30s'}, 'require-encryption': None, 'tls': {'ciphers': None, 'min-version': 1.2, 'max-version': None, 'ca-file': None, 'scheduler': {'cert': None, 'key': None}, 'worker': {'key': None, 'cert': None}, 'client': {'key': None, 'cert': None}}, 'tcp': {'backend': 'tornado'}, 'websockets': {'shard': '8MiB'}}, 'dashboard': {'link': '<a href="https://jupyterhub.hpc.ucar.edu/stable/user/{USER}/FirstTry/proxy/{port}/status">https://jupyterhub.hpc.ucar.edu/stable/user/{USER}/FirstTry/proxy/{port}/status</a>', 'export-tool': False, 'graph-max-items': 5000, 'prometheus': {'namespace': 'dask'}}, 'version': 2, 'nanny': {'preload': [], 'preload-argv': [], 'environ': {'MALLOC_TRIM_THRESHOLD_': 65536, 'OMP_NUM_THREADS': 1, 'MKL_NUM_THREADS': 1}}, 'client': {'heartbeat': '5s', 'scheduler-info-interval': '2s'}, 'deploy': {'lost-worker-timeout': '15s', 'cluster-repr-interval': '500ms'}, 'adaptive': {'interval': '1s', 'target-duration': '5s', 'minimum': 0, 'maximum': inf, 'wait-count': 3}, 'diagnostics': {'nvml': True, 'computations': {'max-history': 100, 'ignore-modules': ['distributed', 'dask', 'xarray', 'cudf', 'cuml', 'prefect', 'xgboost']}}, 'admin': {'tick': {'interval': '20ms', 'limit': '3s'}, 'max-error-length': 10000, 'log-length': 10000, 'log-format': '%(name)s - %(levelname)s - %(message)s', 'pdb-on-err': False, 'system-monitor': {'interval': '500ms'}, 'event-loop': 'tornado'}, 'rmm': {'pool-size': None}}</p>



<a name="49950"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49950" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49950">(Feb 02 2022 at 23:20)</a>:</h4>
<p>I wasn't expecting it to return this much information <span aria-label="smile" class="emoji emoji-1f642" role="img" title="smile">:smile:</span>. Try the following </p>
<div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"distributed.worker.memory"</span><span class="p">)</span>
</code></pre></div>



<a name="49951"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49951" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49951">(Feb 02 2022 at 23:21)</a>:</h4>
<p><span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49950">said</a>:</p>
<blockquote>
<p>I wasn't expecting it to return this much information :). Try the following </p>
<p><div class="codehilite" data-code-language="Python"><pre><span></span><code><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"distributed.worker.memory"</span><span class="p">)</span>
</code></pre></div><br>
</p>
</blockquote>
<p>haha, ok<br>
this looks more reasonable:<br>
{'target': 0.9,<br>
 'spill': False,<br>
 'pause': 0.8,<br>
 'terminate': 0.95,<br>
 'recent-to-old-time': '30s',<br>
 'rebalance': {'measure': 'optimistic',<br>
  'sender-min': 0.3,<br>
  'recipient-max': 0.6,<br>
  'sender-recipient-gap': 0.1}}</p>



<a name="49955"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49955" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49955">(Feb 02 2022 at 23:31)</a>:</h4>
<p>\I was looking for the <code>spill</code> to disk setting and It appears to be off: <code>'spill': False,</code> ( this is the recommended option). </p>
<p>From one of your worker logs, I am seeing that your workers are getting killed by PBS for exceeding the wall time... </p>
<div class="codehilite" data-code-language="Bash"><pre><span></span><code><span class="o">=</span>&gt;&gt; PBS: job killed: walltime <span class="m">7257</span> exceeded limit <span class="m">7200</span>
distributed.dask_worker - INFO - Exiting on signal <span class="m">15</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:46025'</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:39530'</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:40172'</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:33653'</span>
distributed.nanny - INFO - Worker process <span class="m">94660</span> was killed by signal <span class="m">15</span>
distributed.nanny - INFO - Worker process <span class="m">94656</span> was killed by signal <span class="m">15</span>
distributed.nanny - INFO - Worker process <span class="m">94663</span> was killed by signal <span class="m">15</span>
distributed.nanny - INFO - Worker process <span class="m">94653</span> was killed by signal <span class="m">15</span>
distributed.dask_worker - INFO - End worker
</code></pre></div>
<p>I presume these workers are getting killed while they are still trying to write data to netCDF... Is this actually the case? </p>
<p>If Zarr is working for you, please disregard my suggestion of using netCDF... Xarray + dask can hang forever when writing data to netCDF. I don't know why but I've seen it a few times...</p>



<a name="49956"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49956" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49956">(Feb 02 2022 at 23:32)</a>:</h4>
<p><span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49955">said</a>:</p>
<blockquote>
<p>\I was looking for the <code>spill</code> to disk setting and It appears to be off: <code>'spill': False,</code> ( this is the recommended option). </p>
<p>From one of your worker logs, I am seeing that your workers are getting killed by PBS for exceeding the wall time... </p>
<div class="codehilite" data-code-language="Bash"><pre><span></span><code><span class="o">=</span>&gt;&gt; PBS: job killed: walltime <span class="m">7257</span> exceeded limit <span class="m">7200</span>
distributed.dask_worker - INFO - Exiting on signal <span class="m">15</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:46025'</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:39530'</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:40172'</span>
distributed.nanny - INFO - Closing Nanny at <span class="s1">'tcp://10.12.206.65:33653'</span>
distributed.nanny - INFO - Worker process <span class="m">94660</span> was killed by signal <span class="m">15</span>
distributed.nanny - INFO - Worker process <span class="m">94656</span> was killed by signal <span class="m">15</span>
distributed.nanny - INFO - Worker process <span class="m">94663</span> was killed by signal <span class="m">15</span>
distributed.nanny - INFO - Worker process <span class="m">94653</span> was killed by signal <span class="m">15</span>
distributed.dask_worker - INFO - End worker
</code></pre></div>
<p>I presume these workers are getting killed while they are still trying to write data to netCDF... Is this actually the case? </p>
<p>If Zarr is working for you, please disregard my suggestion of using netCDF... Xarray + dask can hang forever when writing data to netCDF. I don't know why but I've seen it a few times...</p>
</blockquote>
<p>OK I'll stick to zarr for now then.<br>
In any case, I don't think I ever got more than 4 workers to launch before the 2hr walltime was exceeded, so I think whatever is being killed never even had a chance to get going.  This has been the case for me for many days, almost a week, now...</p>



<a name="49957"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49957" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49957">(Feb 02 2022 at 23:35)</a>:</h4>
<blockquote>
<p>In any case, I don't think I ever got more than 4 workers to launch before the 2hr walltime was exceeded, so I think whatever is being killed never even had a chance to get going. This has been the case for me for many days, almost a week, now...</p>
</blockquote>
<p>Unfortunately, in some cases, the number of dask workers in your cluster matters, and you might not be able to process the data unless you have enough workers with enough resources (memory-wise). </p>
<p>Can you try running your notebook/analysis on Cheyenne instead of Casper when you get a chance?</p>



<a name="49958"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49958" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49958">(Feb 02 2022 at 23:37)</a>:</h4>
<p>Getting the right resources on Casper can be a headache sometimes especially when so many users are active at the same time...</p>



<a name="49960"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49960" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49960">(Feb 02 2022 at 23:58)</a>:</h4>
<p><span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49958">said</a>:</p>
<blockquote>
<p>Getting the right resources on Casper can be a headache sometimes especially when so many users are active at the same time...</p>
</blockquote>
<p>OK, looks like I can get my 12 workers fairly quickly when using Cheyenne, and in so doing, load the entire dataset.  Still waiting to see if it can write to zarr or if it crashes.</p>



<a name="49962"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49962" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mira Berdahl <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49962">(Feb 03 2022 at 00:29)</a>:</h4>
<p><span class="user-mention silent" data-user-id="259">Mira Berdahl</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49960">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="13">Anderson Banihirwe</span> <a href="#narrow/stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error/near/49958">said</a>:</p>
<blockquote>
<p>Getting the right resources on Casper can be a headache sometimes especially when so many users are active at the same time...</p>
</blockquote>
<p>OK, looks like I can get my 12 workers fairly quickly when using Cheyenne, and in so doing, load the entire dataset.  Still waiting to see if it can write to zarr or if it crashes.</p>
</blockquote>
<p>It takes a while, but this runs on Cheyenne now! Many thanks for your ideas and help here <span class="user-mention" data-user-id="13">@Anderson Banihirwe</span> .</p>



<a name="49965"></a>
<h4><a href="https://zulip2.cloud.ucar.edu#narrow/stream/27-dask/topic/saving%20to%20zarr%20results%20in%20error/near/49965" class="zl"><img src="../../../assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Anderson Banihirwe <a href="../../..//stream/27-dask/topic/saving.20to.20zarr.20results.20in.20error.html#49965">(Feb 03 2022 at 14:39)</a>:</h4>
<p>Glad to hear it <span aria-label="tada" class="emoji emoji-1f389" role="img" title="tada">:tada:</span> and you are welcome!</p>



<hr><p>Last updated: May 16 2025 at 17:14 UTC</p>
</html>