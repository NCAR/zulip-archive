[
    {
        "content": "<p>I'm going to use this topic to track my progress with the MARBL driver. Current status:</p>\n<ol>\n<li>All development is going in via CESM, current branch is based off <code>cesm2_2_alpha04c</code></li>\n<li>MARBL is brought in to <code>pkg/MARBL</code> via <code>manage_externals</code></li>\n<li>MARBL is an optional package; build MOM with <code>-D_USE_MARBL_TRACERS</code> to enable calls to MARBL</li>\n<li>If <code>USE_MARBL_TRACERS = True</code> and the model was NOT built with <code>-D_USE_MARBL_TRACERS</code> then runtime error</li>\n<li>CESM always uses <code>-D_USE_MARBL_TRACERS</code> (will change down the line, but currently adds 20 or 30 seconds to 5+ minute build)</li>\n<li>Currently I do not make any MARBL calls inside the time-stepping loop, but MOM registers the MARBL tracers, initializes them to reasonable values (see <a href=\"https://github.com/mnlevy1981/marbl-forcing/blob/MOM_ic/initial_conditions/gen_mom6_omip_IC.ipynb\" target=\"_blank\" title=\"https://github.com/mnlevy1981/marbl-forcing/blob/MOM_ic/initial_conditions/gen_mom6_omip_IC.ipynb\">https://github.com/mnlevy1981/marbl-forcing/blob/MOM_ic/initial_conditions/gen_mom6_omip_IC.ipynb</a> for details -- mix of WOA and CESM piControl)</li>\n<li>The diagnostics returned from MARBL are registered with MOM, so they can be added to the diag table</li>\n</ol>\n<p>Current question (for <span class=\"user-mention\" data-user-id=\"83\">@Andrew Shao</span> and / or <span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span> ?) -- is there an interface to <code>post_data()</code> where I can send a single column of a 3D field (or a single point of a 2D field) at a time, or do I need to copy each column into a buffer and then post the data once every column has been computed? The issue is that MARBL will overwrite it's diagnostic datatype from the previous column when it moves on to the next column.</p>",
        "id": 7998,
        "sender_full_name": "Michael Levy",
        "timestamp": 1588720811
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>  I am not sure what you are trying to do exactly but we can configure <code>post_data()</code> to send a single column of a 3D field. The code below could be an example:</p>\n<div class=\"codehilite\"><pre><span></span>CS%id_carbon = register_diag_field(&#39;ocean_model&#39;, &#39;carbon&#39;, CS%diag% axesZL, CS%Time, &amp;\n     &#39;carbon concentration&#39;, &#39;units&#39;) ! Note: if axesZL  (a 1-D z-space axis at layer centers) does not work, try axesNull\n\ninteger :: id_carbon = -1\n\nif (CS%id_carbon &gt; 0) call post_data(CS%id_carbon, carbon(i,j,:), CS%diag)\n</pre></div>\n\n\n<p>Please feel free to call me on Google Meet if you want talk about it.</p>",
        "id": 8020,
        "sender_full_name": "Gustavo M Marques",
        "timestamp": 1588794439
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span> -- I'll call you in a few minutes, just wrapping something up. I don't think I was very clear -- I want to register a full 3D field (so <code>diag%axesTL</code>), but post the data one column at a time. Basically, the MARBL driver is going to be computing a single column at a time, and I'd like to post the diagnostics immediately after computing rather than copying them to a buffer and then posting the entire buffer once every column has been computed</p>",
        "id": 8021,
        "sender_full_name": "Michael Levy",
        "timestamp": 1588794574
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span>, <span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span>,  and <span class=\"user-mention\" data-user-id=\"83\">@Andrew Shao</span> : I'm running into an issue that might be purely MARBL, or might be MARBL reacting to something MOM is doing... if any of you have thoughts on how to proceed, I'd appreciate it.</p>\n<p><strong>Background:</strong> I've been testing the MARBL driver by running for a month -- this has let me add output to the monthly history file for investigation, and the runs are taking ~20 minutes so it's not a terribly long wait to look at results. I recently added in a call to MARBL's <code>surface_flux_compute()</code> routine, and in <code>/glade/work/mlevy/codes/CESM/cesm2_2_alpha04c+mom6_marbl/cases/C1850MOMECO.008</code> I was able to run for a month setting tracer values at the surface to 0 and all surface forcing inputs to 1.</p>\n<p><strong>Issue:</strong> In <code>/glade/work/mlevy/codes/CESM/cesm2_2_alpha04c+mom6_marbl/cases/C1850MOMECO.009</code>, I set tracer values at the surface to the actual tracer values MOM is passively advecting around (<code>marbl_instances%tracers_at_surface(1,m) = CS%tr(i,j,1,m)</code>) and now the run crashes during day 7 of the run (at least the coupler gets to midnight on Jan 7, but not midnight on Jan 8). After talking with Gustavo yesterday, I ran with <code>DEBUG=TRUE</code> in <code>/glade/work/mlevy/codes/CESM/cesm2_2_alpha04c+mom6_marbl/cases/C1850MOMECO.009_debug/</code>, but that run seems to pick up unrelated issues (the surface forcing inputs are all 1 instead of 0 because the debug run was flagging some divide-by-zeros that I think came from having atmospheric pressure = 0)</p>\n<p>Anyway, I'm not sure what to make of these runs crashing and I'm having trouble finding any useful information in the logs. Keith, is it possible this relates to me sending non-physical values for the surface forcing fields? Andrew or Gustavo -- is there something special happening to the tracers on day 7 that might hint at why the run is doing fine up until that point?</p>\n<p>I think maybe the next step is to run for 5 days, though I'm not familiar enough with MOM to know how to wholesale change the output frequency of <code>mom6.hm</code> from monthly to more frequent.</p>",
        "id": 8609,
        "sender_full_name": "Michael Levy",
        "timestamp": 1589646892
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span> , I wouldn't be surprised if provided all surface forcing inputs to 1 causes problems.</p>\n<p>I suggest working on the plumbing for forcing inputs, and diagnostic output that of the forcing fields being sent to MARBL, before proceeding with invoking the surface flux computation routine. I can easily see debugging 009 taking a long time. That might not be a good use of time if it boils down to garbage in, garbage out.</p>\n<p>I can see the utility in having checks in MARBL for reasonable forcing inputs. But I don't think that test dev runs in MOM dev is a good platform for coming up with plausible bounds for these checks. Perhaps a time-evolving single column model of MARBL, when it is available, would be a good tool to explore that, as a completely different project.</p>",
        "id": 8610,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1589650196
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>, let me know if you would like discuss this via telecom. I can help you change the output frequency so we can see how the added tracers look like.</p>",
        "id": 8714,
        "sender_full_name": "Gustavo M Marques",
        "timestamp": 1589899675
    },
    {
        "content": "<p>it's been almost a month since the last update, and I wish I had more to say... but I inadvertently \"fixed\" the issue with the surface tracers. I say inadvertently because I'm not sure exactly what fixed it: I updated <code>diag_table</code>, first because I wanted to separate the BGC variables to get more frequent output and then a second time because I realized I was accidentally duplicating a key in the YAML file that generated the table, populated <code>T</code> and <code>S</code> from MOM's state, and removed some un-necessary computation I had copied from the <code>dye_tracer</code>module; the combination of the last two seems to have done the trick. So for surface forcings I'm using</p>\n<div class=\"codehilite\"><pre><span></span>      if (CS%u10_sqr_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%u10_sqr_ind)%field_0d(1) = 2.5e5\n      if (CS%sss_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%sss_ind)%field_0d(1) = tv%S(i,j,1)\n      if (CS%sst_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%sst_ind)%field_0d(1) = tv%T(i,j,1)\n      if (CS%ifrac_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%ifrac_ind)%field_0d(1) = 0\n      if (CS%dust_dep_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%dust_dep_ind)%field_0d(1) = 0\n      if (CS%fe_dep_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%fe_dep_ind)%field_0d(1) = 0\n      if (CS%nox_flux_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%nox_flux_ind)%field_0d(1) = 0\n      if (CS%nhy_flux_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%nhy_flux_ind)%field_0d(1) = 0\n      if (CS%atmpress_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%atmpress_ind)%field_0d(1) = 1\n      if (CS%xco2_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%xco2_ind)%field_0d(1) = 284.7\n      if (CS%xco2_alt_ind &gt; 0) marbl_instances%surface_flux_forcings(CS%xco2_alt_ind)%field_0d(1) = 284.7\n</pre></div>\n\n\n<p>and for tracer surface values:</p>\n<div class=\"codehilite\"><pre><span></span>marbl_instances%tracers_at_surface(1,m) = CS%tr(i,j,1,m)\n</pre></div>\n\n\n<p>Most of the forcing fields need to be updated to either read from files or be passed through the coupler, but at least it's running with reasonable inputs. I think my next two steps are (1) merge in the latest master [I'm hoping that putting all the ecosys diagnostics in a separate stream prevents conflicts in the interface layer] and then (2) setting up memory for saved state. At that point, I'll see about packing multiple columns of data into a single call to <code>surface_flux_compute()</code>.</p>",
        "id": 11209,
        "sender_full_name": "Michael Levy",
        "timestamp": 1591910372
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>  Just FYI, GFDL is experimenting with a new way of supporting external code that might be useful for bringing MARBL<br>\n<a href=\"https://github.com/NOAA-GFDL/MOM6/pull/1133\" target=\"_blank\" title=\"https://github.com/NOAA-GFDL/MOM6/pull/1133\">https://github.com/NOAA-GFDL/MOM6/pull/1133</a></p>",
        "id": 11996,
        "sender_full_name": "Gustavo M Marques",
        "timestamp": 1592518381
    },
    {
        "content": "<p>Ahh sorry, I completely missed this thread (forgot to reload the Zulip app). Glad to hear that is seems to have been resolved. With regard to the GFDL PR, it's basically Alistair going back to the idea of dummy interfaces for all external (including tracer) packages.</p>",
        "id": 12296,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1592935839
    },
    {
        "content": "<p>FYI, I poked around the <code>MOM_OCMIP2_CFC.F90</code> code a bit and it does appear that cfc fluxes are computed in the FMS coupler, not in MOM6. So they don't end up needing to plumb state variables from the atmosphere and sea ice models down into <code>MOM_OCMIP2_CFC.F90</code>, like we are planning to do for MARBL computed surface fluxes.</p>",
        "id": 13273,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1593603152
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> I'm trying to test my code that adds surface flux saved state to the restart file, but having trouble getting expected test failures. Basically, I want to add a variable to the history file, run an ERS test without adding saved state to the restart, and fail the <code>COMPARE_base_rest</code> stage. Then I want to write fields to restart and see that stage of the test pass. Surface PH seemed like a good candidate, since the fields in the restart file are <code>PH_SURF</code> and <code>PH_SURF_ALT_CO2</code>, but even with the <code>PH</code> diagnostic in history file I'm seeing the <code>COMPARE_base_rest</code> pass regardless of whether I write anything into the restart file. Is there a better diagnostic variable to see the effect of saving saved state?</p>",
        "id": 17630,
        "sender_full_name": "Michael Levy",
        "timestamp": 1600699280
    },
    {
        "content": "<p>It seems a little tricky because MOM isn't applying any of the <code>intent(out)</code> variables from MARBL to the tracer state... so I need a value that MARBL outputs as a diagnostic (in POP, I think keeping saved state out of the restarts feeds back to tracer values pretty quickly and then the list of variables that fail the <code>COMPARE_base_rest</code> is large)</p>",
        "id": 17631,
        "sender_full_name": "Michael Levy",
        "timestamp": 1600699458
    },
    {
        "content": "<p>lets talk on zoom</p>",
        "id": 17633,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1600701524
    },
    {
        "content": "<p>Update: I've added <code>STF</code> to the <code>tracer_vertdiff()</code> call via the optional <code>sfc_flux</code> argument; now I'm getting failures in the <code>COMPARE_base_rest</code> for <code>PH</code> whether I add saved state to the restart file or not... I suspect that I am writing the correct values to the restart file but not reading them in upon restart. I'll look a little more this afternoon then add it to the list of things to ask <span class=\"user-mention\" data-user-id=\"83\">@Andrew Shao</span> about if it remains an issue</p>",
        "id": 17663,
        "sender_full_name": "Michael Levy",
        "timestamp": 1600722476
    },
    {
        "content": "<p>It turned out my restart issues were due to registering restart fields too late in the initialization process; I've filed and <a href=\"https://github.com/NOAA-GFDL/MOM6/issues/1214\" target=\"_blank\" title=\"https://github.com/NOAA-GFDL/MOM6/issues/1214\">issue ticket</a> with GFDL asking for an error message in this situation, as I only figured it out because I wondered \"what if I register the saved state restarts earlier in the code\". My branch now passes ERS tests, hooray!</p>\n<p>I'm also putting the finishing touches on getting dust flux and iron flux from the coupler -- once this is done, the to-do list for computing surface fluxes will be pretty short:</p>\n<ol>\n<li>Get ndep forcing fields from file (currently just setting them to 0)</li>\n<li>Refactor code to compute surface fluxes for all columns on MPI task rather than going one at a time</li>\n<li>Add options for forcing fields that POP gets in multiple ways: CO2 concentration only comes in from namelist at the moment, need to be able to get it from the coupler; also iron and dust fluxes only come from coupler, need to be able to read from a file as well</li>\n<li>There's slightly more logic in computing iron flux in POP than in MOM - I added several namelist variables, but have not yet implemented <code>dust_ratio_thres</code> so MOM uses the <code>fe_bioavail_frac_offset</code> parameter everywhere</li>\n<li>MOM6 ignores MARBL's surface_flux_output field -- POP using this type to get CO2 flux and chlorophyll from MARBL</li>\n</ol>\n<p>I'd like to read ndep from a file, but the rest of the tasks can wait until after the driver is calling <code>interior_tendency_compute()</code></p>",
        "id": 17807,
        "sender_full_name": "Michael Levy",
        "timestamp": 1600875388
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"83\">@Andrew Shao</span> (or <span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span> ) -- MARBL needs to know pressure in each column; POP has a function in <code>state_mod.F90</code> that converts from depth (m) -&gt; pressure (bars) using the Levitus 1994 formula:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"c\">!-----------------------------------------------------------------------</span>\n<span class=\"c\">!</span>\n<span class=\"c\">!  convert depth in meters to pressure in bars</span>\n<span class=\"c\">!</span>\n<span class=\"c\">!-----------------------------------------------------------------------</span>\n\n   <span class=\"n\">pressure</span> <span class=\"o\">=</span> <span class=\"mf\">0.059808_r8</span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"nb\">exp</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mf\">0.025_r8</span><span class=\"o\">*</span><span class=\"n\">depth</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">c1</span><span class=\"p\">)</span>     <span class=\"p\">&amp;</span>\n            <span class=\"o\">+</span> <span class=\"mf\">0.100766_r8</span><span class=\"o\">*</span><span class=\"n\">depth</span> <span class=\"o\">+</span> <span class=\"mf\">2.28405e-7_r8</span><span class=\"o\">*</span><span class=\"n\">depth</span><span class=\"o\">**</span><span class=\"mi\">2</span>\n</pre></div>\n\n\n<p>Does MOM have something similar? Or is pressure a state variable that is available on a derived type?</p>",
        "id": 21456,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605291294
    },
    {
        "content": "<p>Pressure will have to be calculated within the MARBL driver. For consistency with everything else it's essentially:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"n\">P</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">h</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">*</span><span class=\"n\">GV</span><span class=\"p\">%</span><span class=\"n\">h_kg_m2</span>\n<span class=\"k\">do </span><span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"n\">nk</span>\n  <span class=\"n\">P</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">)</span> <span class=\"o\">=</span> <span class=\"n\">P</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">h</span><span class=\"o\">*</span><span class=\"n\">GV</span><span class=\"p\">%</span><span class=\"n\">h_kg_m2</span>\n<span class=\"n\">enddo</span>\n</pre></div>",
        "id": 21459,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1605293145
    },
    {
        "content": "<p>That expression is valid for both Boussinesq (where depth is the 'correct' vertical, Cartesian coordinate) and non_Boussinesq modes (where pressure is the 'correct' one)</p>",
        "id": 21460,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1605293266
    },
    {
        "content": "<p>Cool, I'll add the function in <code>MARBL_tracers.F90</code>; as a temporary solution I just computed it in <code>MARBL_tracers_column_physics()</code>:</p>\n<div class=\"codehilite\"><pre><span></span>      <span class=\"c\">!        TODO: In POP, pressure comes from a function in state_mod.F90; I don&#39;t see a similar function here</span>\n      <span class=\"c\">!              This formulation is from Levitus 1994, and I think it belongs in MOM_EOS.F90?</span>\n      <span class=\"c\">!              Converts depth [m] -&gt; pressure [bars]</span>\n      <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">CS</span><span class=\"p\">%</span><span class=\"n\">pressure_ind</span> <span class=\"o\">&gt;</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"n\">marbl_instances</span><span class=\"p\">%</span><span class=\"n\">interior_tendency_forcings</span><span class=\"p\">(</span><span class=\"n\">CS</span><span class=\"p\">%</span><span class=\"n\">pressure_ind</span><span class=\"p\">)%</span><span class=\"n\">field_1d</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,:)</span> <span class=\"o\">=</span> <span class=\"p\">&amp;</span>\n          <span class=\"mf\">0.0598088</span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"nb\">exp</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mf\">0.025</span><span class=\"o\">*</span><span class=\"n\">zc</span><span class=\"p\">(:))</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mf\">0.100766</span><span class=\"o\">*</span><span class=\"n\">zc</span><span class=\"p\">(:)</span> <span class=\"o\">+</span> <span class=\"mf\">2.28405e-7</span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"n\">zc</span><span class=\"p\">(:)</span><span class=\"o\">**</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n</pre></div>",
        "id": 21461,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605293288
    },
    {
        "content": "<p>Within a layer, pressure will vary linearly in both cases</p>",
        "id": 21462,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1605293307
    },
    {
        "content": "<p>Looking in <code>src/core/MOM_verticalGrid.F90</code>, I would have guessed we should be converting with <code>H_to_Pa</code>, and then convert from <code>Pa</code> to <code>bars</code>. Am I misunderstanding?</p>\n<p>Also, it looks like your code computes pressure at the bottom each model layer.<br>\nIf so, and assuming you meant <code>H_to_Pa</code>, would the following be appropriate for layer-averaged pressure?</p>\n<div class=\"codehilite\"><pre><span></span>P_layer_bot = h(1)*GV%H_to_Pa\nP_layer_avg(1) = 0.5 * P_layer_bot\ndo k=2,nk\n  P_layer_top = P_layer_bot\n  P_layer_bot = P_layer_top + h(k)*GV%H_to_Pa\n  P_layer_avg(k) = 0.5 * (P_layer_top + P_layer_bot)\nenddo\n</pre></div>",
        "id": 21513,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1605300735
    },
    {
        "content": "<p>Nice catch Keith, yes it should be <code>H_to_Pa</code> and yes your code is what you would want if you wanted the layer-averaged pressure</p>",
        "id": 21515,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1605302780
    },
    {
        "content": "<p>(I dunno, why my brain thought it was H_to_kg_m2; i must have been staring at another block and went on autopilot :))</p>",
        "id": 21516,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1605302818
    },
    {
        "content": "<p>great, thanks guys! I'll update that computation next; I was just putting in the workaround we talked about where I'll tell MARBL <code>kmt</code> is the bottom-most thick layer to avoid accumulating sediment in a vanishing layer. (Prior to putting the tweak in, the model was crashing with co2calc errors pretty much immediately)</p>",
        "id": 21518,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605303201
    },
    {
        "content": "<p>It looked like the vanishing layers were all 1 mm thick, so I just put in the following kludge that ignores any layers on the bottom less than 1 cm thick:</p>\n<div class=\"codehilite\"><pre><span></span>        <span class=\"c\">! TODO: better way of handling vanishing layers</span>\n        <span class=\"c\">!       (this is a z* workaround for layers that have vanished at bottom of ocean)</span>\n        <span class=\"k\">if</span> <span class=\"p\">((.</span><span class=\"nb\">not</span><span class=\"p\">.</span> <span class=\"n\">set_kmt</span><span class=\"p\">)</span> <span class=\"p\">.</span><span class=\"nb\">and</span><span class=\"p\">.</span> <span class=\"p\">(</span><span class=\"n\">dz</span><span class=\"p\">(</span><span class=\"n\">k</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mf\">0.01</span><span class=\"p\">))</span> <span class=\"k\">then</span>\n<span class=\"k\">          </span><span class=\"n\">set_kmt</span> <span class=\"o\">=</span> <span class=\"p\">.</span><span class=\"n\">true</span><span class=\"p\">.</span>\n          <span class=\"n\">marbl_instances</span><span class=\"p\">%</span><span class=\"n\">domain</span><span class=\"p\">%</span><span class=\"n\">kmt</span> <span class=\"o\">=</span> <span class=\"n\">k</span>\n        <span class=\"k\">end if</span>\n</pre></div>",
        "id": 21520,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605303300
    },
    {
        "content": "<p>that line appears in a loop <code>do k = GV%ke, 1, -1</code>, which is handy for figuring out the smallest <code>k</code> I can ignore</p>",
        "id": 21521,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605303350
    },
    {
        "content": "<p>Do you know which of the tracers was causing <code>co2calc </code>to blowup?</p>",
        "id": 21522,
        "sender_full_name": "Andrew Shao",
        "timestamp": 1605303887
    },
    {
        "content": "<p>I think it was <code>dic</code> or <code>dic_alt_co2</code>, but I'm not 100% sure. I'm adding some location information to the log, and then I'll copy / paste the error (which is triggered on day 5 or 6 even with the KMT kludge)</p>",
        "id": 21523,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605304696
    },
    {
        "content": "<p>So this is the error message MARBL is reporting:</p>\n<div class=\"codehilite\"><pre><span></span>652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_interior_tendency_mod:compute_carbonate_chemistry): Warning reported from marbl_co2calc_interior() with dic_alt_co2\n652:WARNING from PE   580: (Task 580) Message from (lon, lat) (-233.351,  29.892). Level: 18\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) it = 1\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x1,f =  0.1826861E-006-0.5838217E-003\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x2,f =  0.4588866E-006-0.8693591E-003\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) it = 2\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x1,f =  0.1152671E-006-0.4909484E-003\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x2,f =  0.7272863E-006-0.1065694E-002\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) it = 3\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x1,f =  0.4588866E-007-0.3628323E-003\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x2,f =  0.1826861E-005-0.1507087E-002\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) it = 4\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x1,f =  0.7272863E-008-0.6614273E-004\n652:WARNING from PE   580: (Task 580) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x2,f =  0.1152671E-004-0.2108912E-002\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): bounding bracket for pH solution not found\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) dic =  0.1988476E+004\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) ta =  0.2342346E+004\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) pt =  0.2246129E+000\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) sit =  0.4285969E+001\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) temp =  0.1747161E+002\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) salt =  0.3450777E+002\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:comp_htotal): Error reported from drtsafe\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_co2calc_mod:marbl_co2calc_interior): Error reported from comp_htotal()\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_interior_tendency_mod:compute_carbonate_chemistry): Error reported from marbl_co2calc_interior() with dic\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_interior_tendency_mod:marbl_interior_tendency_compute): Error reported from compute_carbonate_chemistry()\n652:WARNING from PE   580: (Task 580) MARBL ERROR (marbl_interface:interior_tendency_compute): Error reported from marbl_interior_tendency_compute()\n652:WARNING from PE   580: (Task 580) MARBL ERROR (MARBL_tracers_column_physics): Error reported from marbl_instances%interior_tendency_compute()\n652:WARNING from PE   580: ERROR reported from MARBL library\n</pre></div>\n\n\n<p><code>DIC</code> and <code>DIC_ALT_CO2</code> are identical, so previous levels in the column are reporting the same warnings about not finding a root in earlier iterations (but they do eventually converge).</p>",
        "id": 21524,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605306157
    },
    {
        "content": "<p>in POP, these errors typically indicate a CFL violation. Given where the development of the MOM driver is, I'm guessing the range of potential issues is significantly larger :) <span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> do the <code>dic</code>, <code>ta</code>, etc values printed out above hint at any potential forcing issues?</p>",
        "id": 21526,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605306331
    },
    {
        "content": "<p>The values don't strike me as being crazy. Could you try running with <code>max_bracket_grow_it = 4</code> in MARBL's <code>marbl_co2calc_mod.F90</code>?</p>",
        "id": 21528,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1605306563
    },
    {
        "content": "<p>increasing <code>max_bracket_grow_it</code> from 3 to 4 let me run a full month. Does this need to be a permanent change in MARBL? Looking through the changes I've made in the MOM driver, the only real issue I can see is that I haven't read in FESEDFLUX yet.</p>",
        "id": 21529,
        "sender_full_name": "Michael Levy",
        "timestamp": 1605308524
    },
    {
        "content": "<p>I do suggest increasing <code>max_bracket_grow_it</code> in MARBL. There have been a few cases where increasing it has enabled some users to run.</p>",
        "id": 21530,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1605321088
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"14\">@Matt Long</span> for <code>FESEDFLUX</code>, the MOM scrip grid file is <code>/glade/p/cesmdata/cseg/mapping/grids/tx0.66v1_SCRIP_190314.nc</code>. The tracer initial conditions file I showed you is <code>/glade/work/mlevy/cesm_inputdata/ecosys_jan_IC_omip_MOM_tx0.66v1_c190925.nc</code> and the vertical dimension / coordinate in that file is named <code>DEPTH</code></p>",
        "id": 22316,
        "sender_full_name": "Michael Levy",
        "timestamp": 1606866032
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>. I am looking into this. First thing I realized is that I had pulled out the Fe sedflux forcing generation into it's own repo:<br>\n<a href=\"https://github.com/marbl-ecosys/forcing-Fe-sedflux\" target=\"_blank\" title=\"https://github.com/marbl-ecosys/forcing-Fe-sedflux\">https://github.com/marbl-ecosys/forcing-Fe-sedflux</a></p>",
        "id": 22388,
        "sender_full_name": "Matt Long",
        "timestamp": 1607011314
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>, I have created two temporary <code>FESEDFLUX</code> forcing files for you:</p>\n<ol>\n<li>/glade/work/mclong/cesm_inputdata/fesedflux_total_reduce_oxic_tx0.66v1.c201204.nc</li>\n<li>/glade/work/mclong/cesm_inputdata/feventflux_5gmol_tx0.66v1.c201204.nc</li>\n</ol>\n<p>Note that there are 2 files; both include the <code>FESEDFLUXIN</code> variable. </p>\n<p>In file (1) there are two additional variables:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"n\">FESEDFLUXIN</span> <span class=\"o\">=</span> <span class=\"n\">FESEDFLUXIN_oxic</span> <span class=\"o\">+</span> <span class=\"n\">FESEDFLUXIN_reduce</span>\n</pre></div>\n\n\n<p>At present, POP simply reads <code>FESEDFLUXIN</code> and ignores the other variables.</p>\n<p>In the future, we may be interested in simulating Fe isotopes and these sources have different signatures, so there may be interest in separating. Please consider this as you build the infrastructure to incorporate this forcing—though the highest priority remains figuring out how to apply this <em>z</em>-level forcing in the ALE context.  </p>\n<p>There are several things I would like to do to clean up the workflow generating this forcing. In lieu of tackling that full workflow now, I have simply regridded the <code>POP_gx1v7</code> forcing to the <code>tx0.66v1</code> grid and to a depth coordinate with 112 vertical levels (extending to 6500 m). </p>\n<p>I think this forcing dataset should be fine for testing and development. Let me know what issues you encounter.</p>\n<p>We will ultimately need to revisit and address the workflow issues I referenced above.</p>",
        "id": 22508,
        "sender_full_name": "Matt Long",
        "timestamp": 1607102299
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"14\">@Matt Long</span>! So to start out I want to read <code>FESEDFLUXIN</code> from both files, convert from <code>umol / m^2 / d</code> -&gt; <code>nmol / cm^2 / s</code>, and then sum the two fields to provide a single forcing field... but in the future we might read <code>FESEDFLUXIN_oxic</code> and <code>FESEDFLUXIN_reduce</code> separately so it'll be good to have those fields in the forcing file?</p>",
        "id": 22509,
        "sender_full_name": "Michael Levy",
        "timestamp": 1607103580
    },
    {
        "content": "<p>(It looks like POP modifies the fevent file to add all values below the ocean floor to the KMT level; I'm not entirely clear on how that would map to z* but initially I'll just focus on getting the fields read and remapped)</p>",
        "id": 22510,
        "sender_full_name": "Michael Levy",
        "timestamp": 1607103715
    },
    {
        "content": "<blockquote>\n<p>Convert from <code>umol / m^2 / d</code> -&gt; <code>nmol / cm^2 / s</code></p>\n</blockquote>\n<p>In POP we have the following in the namelist</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"n\">fesedflux_input</span><span class=\"p\">%</span><span class=\"n\">scale_factor</span> <span class=\"o\">=</span> <span class=\"mf\">1.1574e-6</span>\n</pre></div>\n\n\n<p>which is the conversion to <code>umol / m^2 / d</code> -&gt; <code>nmol / cm^2 / s</code>.</p>\n<blockquote>\n<p>...and then sum the two fields to provide a single forcing field... but in the future we might read <code>FESEDFLUXIN_oxic</code> and <code>FESEDFLUXIN_reduce</code> separately so it'll be good to have those fields in the forcing file?</p>\n</blockquote>\n<p>The total is already in the file, so if expedient, just read that. Otherwise reading separately and summing is good.</p>",
        "id": 22511,
        "sender_full_name": "Matt Long",
        "timestamp": 1607104681
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>, btw this is the notebook that created those files:<br>\n<a href=\"https://github.com/marbl-ecosys/forcing-Fe-sedflux/blob/mom6-dev/notebooks/preliminary_MOM6_forcing.ipynb\" target=\"_blank\" title=\"https://github.com/marbl-ecosys/forcing-Fe-sedflux/blob/mom6-dev/notebooks/preliminary_MOM6_forcing.ipynb\">https://github.com/marbl-ecosys/forcing-Fe-sedflux/blob/mom6-dev/notebooks/preliminary_MOM6_forcing.ipynb</a></p>",
        "id": 22512,
        "sender_full_name": "Matt Long",
        "timestamp": 1607106231
    },
    {
        "content": "<p>FYI, there is a <a href=\"https://github.com/NOAA-GFDL/MOM6/pull/1268\" target=\"_blank\" title=\"https://github.com/NOAA-GFDL/MOM6/pull/1268\">PR</a> in the <a href=\"https://github.com/NOAA-GFDL/MOM6\" target=\"_blank\" title=\"https://github.com/NOAA-GFDL/MOM6\">NOAA-GFDL/MOM6 repo</a> that, among other things, changes the API of <code>tracer_Z_init</code>. I'm not sure when the PR is projected to be merged. It looks like it will be straightforward to update the MARBL driver when that update eventually gets to the NCAR MOM6 repo.</p>\n<p>It might be prudent to follow that NOAA-GFDL/MOM6 repo in order to be aware of MOM6 changes in the works.</p>",
        "id": 22969,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1607714441
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"83\">@Andrew Shao</span> and I were code up a rough implementation of mapping FESEDFLUX from the WOA z-grid to the MOM grid; we had a couple of mis-steps along the way, and I needed to bump <code>max_bracket_grow_it</code> from 4 to 5, but I now have a MOM history file where the <code>FESEDFLUX</code> field has some non-zero values: <code>/glade/scratch/mlevy/C1850MOMECO.041/run/C1850MOMECO.041.mom6.hm_bgc_0001_01.nc</code></p>\n<p>For the conservation property, I need to verify that the column sum on the MOM grid matches the column sum in the obs right?</p>",
        "id": 23276,
        "sender_full_name": "Michael Levy",
        "timestamp": 1608306324
    },
    {
        "content": "<p>Yes, those are the correct quantities to compare to check conservation.</p>",
        "id": 23297,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1608316571
    },
    {
        "content": "<p>Regarding reading time-varying ndep from a file,  CDEPS (yet another repo to follow) has a <a href=\"https://github.com/ESCOMP/CDEPS/issues/36\" target=\"_blank\" title=\"https://github.com/ESCOMP/CDEPS/issues/36\">PR</a> to pass ndep from datm. If that PR gets addressed sooner rather than later, then the ability to read time-varying ndep from a file could have its priority lowered.</p>\n<p>In the mean time, it might make sense to read ndep from an annual mean file instead of effectively using a perpetual January mean.</p>",
        "id": 23398,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1608749455
    },
    {
        "content": "<p>Just to follow up on reading nitrogen deposition from a climatology -- I followed <span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span>'s advice, and used <code>time_interp_external()</code> to read the data. I needed to clean up the forcing file a little bit. Some was trivial, like adding the <code>axis</code> attribute to coordinate variables, but I also needed to use 1D arrays for <code>LAT</code> and <code>LON</code> instead of the 2D arrays that come from the displaced pole grid. I'm not sure of the best way to verify that the deposition fields are being interpolated correctly, but maybe on Monday I'll run a full year and make sure <code>NHx_FLUX</code> and <code>NOy_FLUX</code> vary from month to month in a similar manner to the forcing fields.</p>\n<p>I think this was the last hurdle to actually running MARBL + MOM with the default MOM tunings; next week I'll start work on making it easier to control the BGC output. Once we can get more output from MARBL into netCDF files, does it make sense to look at a multi-year C or G case to verify the model can run that long and the output looks reasonable? I can launch a run and then work on getting <code>user_nl_marbl</code> set so we can try to tune the model.</p>",
        "id": 23817,
        "sender_full_name": "Michael Levy",
        "timestamp": 1610148954
    },
    {
        "content": "<p>Following up on the current implementation to read NDEP forcing (via <code>time_interp_external()</code>): I ran for three years in <code>/glade/scratch/mlevy/C1850MOMECO.044/run</code> and have confirmed that</p>\n<ol>\n<li><code>NOx_FLUX</code> changes from month to month within a given year (e.g. <code>0001-01</code> is different than <code>0001-08</code>)</li>\n<li><code>NOx_FLUX</code> does NOT change from year to year for a given month (e.g. <code>0001-03</code> is identical to <code>0003-03</code>). The exception is that there is a small (O(1e-10)) difference between <code>0001-01</code> and <code>0002-01</code>, while <code>0003-01</code> is identical to the latter. I assume that MOM6 starts on the second coupling interval in CESM? So years 0002 and 0003 include the 12:00a - 1:00a window on January first while the first year starts at 1:00a?</li>\n</ol>",
        "id": 23956,
        "sender_full_name": "Michael Levy",
        "timestamp": 1610686009
    },
    {
        "content": "<p>My conclusion from the above is that <code>time_interp_external()</code> is reading climatological data exactly the way we expect it to</p>",
        "id": 23957,
        "sender_full_name": "Michael Levy",
        "timestamp": 1610686046
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>, here are two riverine nutrient forcing data files for MOM<br>\nIn this directory:<br>\n/glade/work/mclong/cesm_inputdata</p>\n<ul>\n<li><a href=\"http://riv_nut.gnews_gnm.JRA025m_to_tx0.66v1_nnsm_e333r100_190910.20210401.nc\" target=\"_blank\" title=\"http://riv_nut.gnews_gnm.JRA025m_to_tx0.66v1_nnsm_e333r100_190910.20210401.nc\">riv_nut.gnews_gnm.JRA025m_to_tx0.66v1_nnsm_e333r100_190910.20210401.nc</a></li>\n<li><a href=\"http://riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.20210401.nc\" target=\"_blank\" title=\"http://riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.20210401.nc\">riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.20210401.nc</a></li>\n</ul>",
        "id": 28296,
        "sender_full_name": "Matt Long",
        "timestamp": 1617309351
    },
    {
        "content": "<p>Awesome, thanks! I should be able to test them out tomorrow and let you know how things look</p>",
        "id": 28297,
        "sender_full_name": "Michael Levy",
        "timestamp": 1617309388
    },
    {
        "content": "<p>Let me know if you see any anomalies. For the time-being, I included a field called <code>TAREA</code> as my code is setup to integrate using that variable (in cm^2). Would be good to fix this—as well as the fake 1D coordinate issue we discussed.</p>",
        "id": 28298,
        "sender_full_name": "Matt Long",
        "timestamp": 1617309422
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"14\">@Matt Long</span> the file you created includes <code>LAT</code> and <code>LON</code> dimensions, but also has <code>nlat</code> and <code>nlon</code> (used by the variables we want to read). With some selective editing:</p>\n<div class=\"codehilite\"><pre><span></span>$ ncdump -h /glade/work/mclong/cesm_inputdata/riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.20210401.nc\nnetcdf riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.20210401 {\ndimensions:\n        LAT = 458 ;\n        LON = 540 ;\n        time = UNLIMITED ; // (21 currently)\n        nlat = 458 ;\n        nlon = 540 ;\nvariables:\n        double LAT(LAT) ;\n                LAT:_FillValue = NaN ;\n                LAT:long_name = &quot;latitude&quot; ;\n                LAT:units = &quot;degrees_north&quot; ;\n                LAT:axis = &quot;Y&quot; ;\n        double LON(LON) ;\n                LON:_FillValue = NaN ;\n                LON:long_name = &quot;longitude&quot; ;\n                LON:units = &quot;degrees_east&quot; ;\n                LON:axis = &quot;X&quot; ;\n        double din_riv_flux(time, nlat, nlon) ;\n                din_riv_flux:_FillValue = 9.96920996838687e+36 ;\n                din_riv_flux:long_name = &quot;River flux of DIN&quot; ;\n                din_riv_flux:units = &quot;nmol/cm^2/s&quot; ;\n</pre></div>\n\n\n<p>(same is true on the <code>JRA025</code> grid). Any chance you could regenerate these without <code>nlat</code> and <code>nlon</code>? I can't figure out the NCO magic needed to fix this,  <code>ncrename -d nlat,LAT -d nlon,LON</code> doesn't seem to be the right tool for the job:</p>\n<div class=\"codehilite\"><pre><span></span>ERROR: nco_rename_dim() cannot define dimension name &quot;LAT&quot; which is already in use\nnco_err_exit(): ERROR Short NCO-generated message (usually name of function that triggered error): nco_rename_dim()\nnco_err_exit(): ERROR Error code is -42. Translation into English with nc_strerror(-42) is &quot;NetCDF: String match to name in use&quot;\nnco_err_exit(): ERROR NCO will now exit with system call exit(EXIT_FAILURE)\n</pre></div>",
        "id": 28427,
        "sender_full_name": "Michael Levy",
        "timestamp": 1617399948
    },
    {
        "content": "<p>yes, I can fix this</p>",
        "id": 28428,
        "sender_full_name": "Matt Long",
        "timestamp": 1617400002
    },
    {
        "content": "<p>Thanks! I also needed to add a couple attributes to the <code>time</code> variable: <code>axis = \"T\"</code> and <code>cartesian_axis = \"T\"</code> -- if you're regenerating the files anyway, could we add those two, uh, too?</p>",
        "id": 28429,
        "sender_full_name": "Michael Levy",
        "timestamp": 1617400186
    },
    {
        "content": "<p>yep, sorry I missed those</p>",
        "id": 28430,
        "sender_full_name": "Matt Long",
        "timestamp": 1617400223
    },
    {
        "content": "<p>River fluxes: I wrote a quick python function to generate the output I thought I needed:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"k\">def</span> <span class=\"nf\">generate_updated_file</span><span class=\"p\">(</span><span class=\"n\">filename</span><span class=\"p\">,</span> <span class=\"n\">inputdir</span><span class=\"p\">,</span> <span class=\"n\">out_dir</span><span class=\"p\">,</span> <span class=\"n\">varlist</span><span class=\"p\">):</span>\n    <span class=\"n\">ds_in</span> <span class=\"o\">=</span> <span class=\"n\">xr</span><span class=\"o\">.</span><span class=\"n\">open_dataset</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">inputdir</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">),</span> <span class=\"n\">decode_times</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># 1. Construct new dataset from coords of second dataset</span>\n    <span class=\"n\">coords</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;LAT&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;LON&quot;</span><span class=\"p\">]</span>\n    <span class=\"n\">ds</span> <span class=\"o\">=</span> <span class=\"n\">ds_in</span><span class=\"p\">[[</span><span class=\"n\">var</span> <span class=\"k\">for</span> <span class=\"n\">var</span> <span class=\"ow\">in</span> <span class=\"n\">coords</span> <span class=\"k\">if</span> <span class=\"n\">var</span> <span class=\"o\">!=</span> <span class=\"s2\">&quot;time&quot;</span><span class=\"p\">]]</span>\n\n    <span class=\"c1\">#    * Time coordinate needs this kludge for now</span>\n    <span class=\"c1\">#      i.  I don&#39;t know how to tell MOM to read from 1900 (POP uses shr_stream_year_start / shr_stream_year_align) so I subtract 1899 years from time dimension</span>\n    <span class=\"c1\">#      ii. I don&#39;t know how to tell MOM to use the first value for dates before day 181.5, so I subtract 181.5 days</span>\n    <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">ds_in</span><span class=\"p\">[</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"mi\">1899</span><span class=\"o\">*</span><span class=\"mi\">365</span> <span class=\"o\">-</span> <span class=\"mf\">181.5</span>\n\n    <span class=\"c1\"># 2. Copy necessary variables over, dropping _FillValue encoding</span>\n    <span class=\"k\">for</span> <span class=\"n\">var</span> <span class=\"ow\">in</span> <span class=\"n\">varlist</span><span class=\"p\">:</span>\n        <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">xr</span><span class=\"o\">.</span><span class=\"n\">DataArray</span><span class=\"p\">(</span><span class=\"n\">ds_in</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"p\">,</span> <span class=\"n\">dims</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;LAT&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;LON&quot;</span><span class=\"p\">])</span>\n        <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attrs</span> <span class=\"o\">=</span> <span class=\"n\">ds_in</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attrs</span>\n        <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">encoding</span><span class=\"p\">[</span><span class=\"s2\">&quot;_FillValue&quot;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n\n    <span class=\"c1\"># 3. Update coordinate attributes</span>\n    <span class=\"c1\">#    i. Make sure they match original file</span>\n    <span class=\"c1\">#    ii. Drop _FillValue encoding</span>\n    <span class=\"c1\">#    iii. Add necessary attributes for time dimension</span>\n    <span class=\"k\">for</span> <span class=\"n\">var</span> <span class=\"ow\">in</span> <span class=\"n\">coords</span><span class=\"p\">:</span>\n        <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attrs</span> <span class=\"o\">=</span> <span class=\"n\">ds_in</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attrs</span>\n        <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"n\">var</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">encoding</span><span class=\"p\">[</span><span class=\"s2\">&quot;_FillValue&quot;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>\n    <span class=\"c1\"># Some fixes for time</span>\n    <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attrs</span><span class=\"p\">[</span><span class=\"s2\">&quot;axis&quot;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;T&quot;</span>\n    <span class=\"n\">ds</span><span class=\"p\">[</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">attrs</span><span class=\"p\">[</span><span class=\"s2\">&quot;cartesian_axis&quot;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;T&quot;</span>\n\n    <span class=\"c1\"># 4. Write to disk</span>\n    <span class=\"n\">ds</span><span class=\"o\">.</span><span class=\"n\">to_netcdf</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">out_dir</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"p\">),</span> <span class=\"n\">unlimited_dims</span><span class=\"o\">=</span><span class=\"s2\">&quot;time&quot;</span><span class=\"p\">,</span> <span class=\"nb\">format</span><span class=\"o\">=</span><span class=\"s2\">&quot;NETCDF3_64BIT&quot;</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;DONE: </span><span class=\"si\">{filename}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n</pre></div>\n\n\n<p>And I think I have all the infrastructure in place to read in the file and apply fields to the STF. However, it looks pretty far off from the POP datasets. Comparing <code>/glade/p/cesmdata/cseg/inputdata/ocn/pop/gx1v7/forcing/riv_nut.gnews_gnm.rx1_to_gx1v7_nn_open_ocean_nnsm_e1000r300_marginal_sea_170413.20190602.nc</code> and <code>/glade/work/mclong/cesm_inputdata/riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.20210401.nc</code> shows that fields like <code>alk_riv_flux</code> differ by a couple orders of magnitude. Is this expected since we're using the smooth map in the open ocean rather than nearest neighbor? I'm still seeing very low tracer values at the mouth of rivers, and the \"MOM with runoff\" output is much more similar to the \"MOM without runoff\" output than the POP output.</p>\n<p>MOM run without runoff: <code>/glade/scratch/mlevy/C1850MOMECO.057/run</code><br>\nMOM run with runoff: <code>/glade/scratch/mlevy/C1850MOMECO.063/run</code><br>\nPOP run: <code>/glade/scratch/mlevy/C1850ECO.pop_defaults/run</code></p>\n<p>MOM monthly output for January is in <code>{CASE}.mom6.hm_bgc_monthly_0001_01.nc</code> and <code>{CASE}.mom6.hm_bgc_monthly_z_0001_01.nc</code> (former has 2D fields, latter has 3D)</p>",
        "id": 28460,
        "sender_full_name": "Michael Levy",
        "timestamp": 1617468775
    },
    {
        "content": "<p>New files here /glade/work/mclong/cesm_inputdata</p>\n<ul>\n<li><a href=\"http://riv_nut.gnews_gnm.JRA025m_to_tx0.66v1_nnsm_e333r100_190910.20210405.nc\" target=\"_blank\" title=\"http://riv_nut.gnews_gnm.JRA025m_to_tx0.66v1_nnsm_e333r100_190910.20210405.nc\">riv_nut.gnews_gnm.JRA025m_to_tx0.66v1_nnsm_e333r100_190910.20210405.nc</a></li>\n<li><a href=\"http://riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.nc\" target=\"_blank\" title=\"http://riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.nc\">riv_nut.gnews_gnm.rx1_to_tx0.66v1_nnsm_e1000r300_190315.nc</a></li>\n</ul>\n<p>Note that the flux units have changed, now in mmol/m^2/s.</p>",
        "id": 28517,
        "sender_full_name": "Matt Long",
        "timestamp": 1617648766
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span> or <span class=\"user-mention\" data-user-id=\"98\">@Alper Altuntas</span> -- it looks like something has changed with the Workflows portion of <a href=\"https://github.com/NCAR/MOM6\" target=\"_blank\" title=\"https://github.com/NCAR/MOM6\">https://github.com/NCAR/MOM6</a> -- <a href=\"https://github.com/NCAR/MOM6/pull/157\" target=\"_blank\" title=\"https://github.com/NCAR/MOM6/pull/157\">my PR</a> says \"First-time contributors need a maintainer to approve running workflows\" even though the workflow ran automatically for the previous two commits.</p>",
        "id": 30193,
        "sender_full_name": "Michael Levy",
        "timestamp": 1619207312
    },
    {
        "content": "<p>Also, when I run the <a href=\"https://github.com/mnlevy1981/MOM6/runs/2422744825\" target=\"_blank\" title=\"https://github.com/mnlevy1981/MOM6/runs/2422744825\">Expression Verification</a> test, I'm getting a lot of failures like</p>\n<div class=\"codehilite\"><pre><span></span>work/tc1.b/symmetric/chksum_diag work/tc1.b/dim.z/chksum_diag differ: byte 103194, line 1245\n1245,1248c1245,1248\n&lt; h-point: mean=   5.3175737620383399E+06 min=   2.2836111531271545E+03 max=   2.4117120854396626E+07 ocean_model-T_zint\n&lt; h-point: c=      2316 ocean_model-T_zint\n&lt; h-point: mean=   4.4396160250802070E+05 min=   2.2836111531271545E+03 max=   2.5004806607685145E+06 ocean_model-T_zint_100m\n&lt; h-point: c=      2382 ocean_model-T_zint_100m\n---\n&gt; h-point: mean=   2.5964715634952831E+03 min=   1.1150445083628684E+00 max=   1.1775937917185853E+04 ocean_model-T_zint\n&gt; h-point: c=      2372 ocean_model-T_zint\n&gt; h-point: mean=   2.5964715634952831E+03 min=   1.1150445083628684E+00 max=   1.1775937917185853E+04 ocean_model-T_zint_100m\n&gt; h-point: c=      2372 ocean_model-T_zint_100m\n1309,1312c1309,1312\n&lt; h-point: mean=   4.2729781503789179E+07 min=   1.8112499999999993E+04 max=   1.8646968871361169E+08 ocean_model-S_zint\n&lt; h-point: c=      3052 ocean_model-S_zint\n&lt; h-point: mean=   1.5499771875000000E+06 min=   1.8112499999999993E+04 max=   3.6225000000000009E+06 ocean_model-S_zint_100m\n&lt; h-point: c=      2690 ocean_model-S_zint_100m\n---\n&gt; h-point: mean=   2.0864151124897060E+04 min=   8.8439941406249964E+00 max=   9.1049652692193209E+04 ocean_model-S_zint\n&gt; h-point: c=      2980 ocean_model-S_zint\n&gt; h-point: mean=   2.0864151124897060E+04 min=   8.8439941406249964E+00 max=   9.1049652692193209E+04 ocean_model-S_zint_100m\n&gt; h-point: c=      2980 ocean_model-S_zint_100m\nFAIL: Diagnostics tc1.b.dim.z.diag have changed.\n</pre></div>\n\n\n<p>I'm not sure what part of the code I could have inadvertently modified to cause this kind of failure -- any ideas on where I should look? Or are my baselines out of date somehow? I merged <a href=\"https://github.com/NCAR/MOM6/releases/tag/dev%2Fncar_20210409\" target=\"_blank\" title=\"https://github.com/NCAR/MOM6/releases/tag/dev%2Fncar_20210409\"><code>dev/ncar_20210409</code></a> onto my branch and it looks like there's been more activity to <code>dev/ncar</code> since then.</p>",
        "id": 30200,
        "sender_full_name": "Michael Levy",
        "timestamp": 1619208272
    },
    {
        "content": "<p>The change came in when we merged the main branch.  MOM6 used to be tested via Travis and now this is done via Github actions. Should I click on \"Approve and run\"?</p>",
        "id": 30201,
        "sender_full_name": "Gustavo M Marques",
        "timestamp": 1619208392
    },
    {
        "content": "<p>I clicked on \"Approve and run\" and the tests are now running. <br>\nOn your section question, perhaps your baseline is out of date.  Maybe merging ned/ncar will fix these failures.</p>",
        "id": 30203,
        "sender_full_name": "Gustavo M Marques",
        "timestamp": 1619208813
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"15\">@Gustavo M Marques</span> actually, it looks like it's probably a bug on my end -- <code>_zint</code> and <code>_zint_100m</code> are new diagnostics I introduced to the tracer package, and I suspect I'm not doing the unit conversion correctly (but at least it's being caught by the testing!)</p>",
        "id": 30208,
        "sender_full_name": "Michael Levy",
        "timestamp": 1619213735
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>, <span class=\"user-mention\" data-user-id=\"14\">@Matt Long</span> , <span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> <br>\n<a href=\"https://github.com/NOAA-GFDL/MOM6/blob/350809a205bd914e176fd115385c9d409174b97d/src/parameterizations/vertical/MOM_geothermal.F90\" target=\"_blank\" title=\"https://github.com/NOAA-GFDL/MOM6/blob/350809a205bd914e176fd115385c9d409174b97d/src/parameterizations/vertical/MOM_geothermal.F90\">Here</a> is the geothermal module for MOM6.</p>",
        "id": 32684,
        "sender_full_name": "Gustavo M Marques",
        "timestamp": 1622053477
    },
    {
        "content": "<p>I'm trying to remove what we've been calling the \"KMT kludge\" -- to avoid issues with vanishing layers at the bottom of the column, we had told MARBL that the number of columns is the index of the deepest layer that is more than 1 cm thick (so if layers 64 and 65 were extremely thin, we told MARBL that <code>kmt = 63</code>). This was necessary because we were converting a bottom flux (sinking matter hitting the sea floor and being remineralized) to a tendency by simply dividing by dz in the bottom layer. We now have a better scheme for that computation based on a pre-computed vertical diffusion profile so I tried to run with every column (using <code>kmt = GV%ke</code>) but got the typical <code>marbl_co2calc_mod.F90</code> error that I usually associate with a CFL violation:</p>\n<div class=\"codehilite\"><pre><span></span>284:WARNING from PE   212: (Task 212) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) it = 4\n284:WARNING from PE   212: (Task 212) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x1,f =  0.7752463E-008-0.2265376E-004\n284:WARNING from PE   212: (Task 212) MARBL WARNING (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) x2,f =  0.1228683E-004-0.2126109E-002284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): bounding bracket for pH solution not found\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) dic =  0.2097770E+004\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) ta =  0.2325961E+004\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) pt =  0.9106563E+000\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) sit =  0.4590227E+001\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) temp =  0.9627328E+001\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:drtsafe): (marbl_co2calc_mod:drtsafe) salt =  0.3368320E+002\n284:WARNING from PE   212: (Task 212) MARBL ERROR (marbl_co2calc_mod:comp_htotal): Error reported from drtsafe\n</pre></div>\n\n\n<p>This is happening in <code>/glade/work/mlevy/codes/CESM/cesm2_3_alpha02d+mom_marbl/cases/C1850MOMECO.079</code> (rundir is <code>/glade/scratch/mlevy/C1850MOMECO.079/run</code>); 9332129 was run with <code>max_bracket_grow_it = 3</code>, and I'm currently rebuilding with <code>max_bracket_grow_it = 5</code> but if anyone has ideas about other parts of the code that may be causing problems by dividing by <code>dz</code> when <code>dz</code> is close to zero I'm not sure where else to look for issues.</p>",
        "id": 36882,
        "sender_full_name": "Michael Levy",
        "timestamp": 1625893800
    },
    {
        "content": "<p>9333054 is running with the increased <code>max_bracket_grow_it</code>, and it's gotten through a few days already (9332129 aborted in the first day) so it may have just taken an extra iteration or two in a thin layer to get past this. <span aria-label=\"fingers crossed\" class=\"emoji emoji-1f91e\" role=\"img\" title=\"fingers crossed\">:fingers_crossed:</span></p>",
        "id": 36883,
        "sender_full_name": "Michael Levy",
        "timestamp": 1625894658
    },
    {
        "content": "<p>This is encouraging. A class of things, but not the only things, to look at are the BGC values in the thin layers, to see if they have values considerably different from the values in adjacent non-thin layers. Could you do a multi-month run with BGC 3D variables on the \"ocean_model\" vertical axis, instead of \"ocean_model_z\".</p>",
        "id": 36884,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1625927643
    },
    {
        "content": "<blockquote>\n<p>This is encouraging. A class of things, but not the only things, to look at are the BGC values in the thin layers, to see if they have values considerably different from the values in adjacent non-thin layers. Could you do a multi-month run with BGC 3D variables on the \"ocean_model\" vertical axis, instead of \"ocean_model_z\".</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> I set up <code>/glade/scratch/mlevy/C1850MOMECO.080/run</code> to run for six months -- there will still be a file with the <code>hm_bgc_monthly_z</code> stream name, but the fields inside that file will be written on the native grid rather than vertically interpolated (I figured for a one-off experiment, it would be easier to explain the inconsistent file name than try to remember how to move variables between streams). It's currently in the queue, and I'll keep an eye on it to make sure it actually runs</p>",
        "id": 36885,
        "sender_full_name": "Michael Levy",
        "timestamp": 1625934301
    },
    {
        "content": "<p>I squeezed in a few more runs before the NWSC shutdown this week; <code>/glade/scratch/mlevy/C1850MOMECO.085/run</code> has 6 months of output, with monthly 3D variables output both on the model grid and regridded to the standard vertical grid (<code>mom6.hm_bgc_monthly_z_YYYY_MM.nc</code> and <code>mom6.h_bgc_monthly_z_YYYY_MM.nc</code>, respectively). This code does not have the KMT kludge in it, and also updates the default value of <code>MIX_BOUNDARY_TRACER_ALE</code> to force a minimum diffusivity in vanishing layers at the bottom of columns... so the weights we pass to MARBL are reasonable.</p>\n<p>The bad news is that I can't get MOM+MARBL running on izumi, so I don't think there's much I can do while cheyenne is down. I'll poke through my logs on izumi and see if I can figure out what the problem is, but even after increasing <code>NTASKS_OCN</code> (the default PE layout was only running MOM on 144 cores) I couldn't get through a model day. <span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> -- given the improvement we saw by updating <code>MIX_BOUNDARY_TRACER_ALE</code>, can I merge <a href=\"https://github.com/marbl-ecosys/MARBL/pull/381\" target=\"_blank\" title=\"https://github.com/marbl-ecosys/MARBL/pull/381\">#381</a> into MARBL?</p>",
        "id": 38585,
        "sender_full_name": "Michael Levy",
        "timestamp": 1627269293
    },
    {
        "content": "<p>Some plots looking at the effect of changing <code>MIX_BOUNDARY_TRACER_ALE</code> are in <a href=\"https://github.com/mnlevy1981/MARBL-notebooks/blob/master/MOM6_MIX_BOUNDARY_TRACER_ALE.ipynb\" target=\"_blank\" title=\"https://github.com/mnlevy1981/MARBL-notebooks/blob/master/MOM6_MIX_BOUNDARY_TRACER_ALE.ipynb\">a notebook on github</a></p>",
        "id": 38586,
        "sender_full_name": "Michael Levy",
        "timestamp": 1627270684
    },
    {
        "content": "<p>Continuing the investigation into differences in the <code>Fe</code> tracer between MOM and POP, I ran without any river fluxes and without iron sediment flux... still seeing a big difference in iron at the surface, especially in the tropics (this is an average over a one-year run, hastily done without weighting by days per month):</p>\n<p><a href=\"/user_uploads/2/1f/JSVkFfwpPs7GU6bOStMiRFRG/Fe-zonal-mean.png\">Fe-zonal-mean.png</a></p>\n<p>Looking at maps of surface values, the west coast of Africa stands out as a big difference. POP has <code>z_t</code> in the title, MOM has <code>z_pop_l</code>:</p>\n<p><a href=\"/user_uploads/2/43/J1tCrOhQhpkfjRtJbGiaEebW/Fe-map-POP.png\">Fe-map-POP.png</a><br>\n<a href=\"/user_uploads/2/5b/SaqyH-XymQX-c3CHnzrx21MF/Fe-map-MOM.png\">Fe-map-MOM.png</a></p>\n<p>It looks like there are differences in the <code>IRON_FLUX</code> field. POP map follows zonal mean, MOM map is last:</p>\n<p><a href=\"/user_uploads/2/3c/HDvfHzxJlANybhBYAroT7pdp/IRON_FLUX-zonal-mean.png\">IRON_FLUX-zonal-mean.png</a><br>\n<a href=\"/user_uploads/2/ab/1B4Nw_D1ai4Z95MqxM3B2jN7/IRON_FLUX-POP.png\">IRON_FLUX-POP.png</a><br>\n<a href=\"/user_uploads/2/65/nxyCdCJhHQcA0rrTe67HuT2V/IRON_FLUX-MOM.png\">IRON_FLUX-MOM.png</a></p>\n<p>edit: weird, I was expecting the images to be inlined rather than linked.</p>",
        "id": 46269,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636041961
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span>—this makes sense.  I presume you can track down where these differences arise in the driver setup/configuration.  We typically run with <code>driver_derived</code> forcing and there are multiple places in POP involved in the <code>IRON_FLUX</code> computation.</p>",
        "id": 46286,
        "sender_full_name": "Matt Long",
        "timestamp": 1636049111
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"14\">Matt Long</span> <a href=\"#narrow/stream/9-MOM6-dev/topic/MARBL.20driver.20for.20MOM6/near/46286\">said</a>:</p>\n<blockquote>\n<p>Thanks <span class=\"user-mention silent\" data-user-id=\"10\">Michael Levy</span>—this makes sense.  I presume you can track down where these differences arise in the driver setup/configuration.  We typically run with <code>driver_derived</code> forcing and there are multiple places in POP involved in the <code>IRON_FLUX</code> computation.</p>\n</blockquote>\n<p>Yeah, it looks like I'm using C-compset defaults for a few parameters that have different settings in POP for G compsets:</p>\n<div class=\"codehilite\" data-code-language=\"XML\"><pre><span></span><code><span class=\"nt\">&lt;dust_ratio_thres&gt;</span>60.0<span class=\"nt\">&lt;/dust_ratio_thres&gt;</span>\n<span class=\"nt\">&lt;dust_ratio_thres</span> <span class=\"na\">ocn_coupling=</span><span class=\"s\">\"partial\"</span><span class=\"nt\">&gt;</span>69.00594<span class=\"nt\">&lt;/dust_ratio_thres&gt;</span>\n\n<span class=\"nt\">&lt;fe_bioavail_frac_offset&gt;</span>0.01<span class=\"nt\">&lt;/fe_bioavail_frac_offset&gt;</span>\n<span class=\"nt\">&lt;fe_bioavail_frac_offset</span> <span class=\"na\">ocn_coupling=</span><span class=\"s\">\"partial\"</span><span class=\"nt\">&gt;</span>0.0146756<span class=\"nt\">&lt;/fe_bioavail_frac_offset&gt;</span>\n\n<span class=\"nt\">&lt;dust_ratio_to_fe_bioavail_frac_r&gt;</span>170.0<span class=\"nt\">&lt;/dust_ratio_to_fe_bioavail_frac_r&gt;</span>\n<span class=\"nt\">&lt;dust_ratio_to_fe_bioavail_frac_r</span> <span class=\"na\">ocn_coupling=</span><span class=\"s\">\"partial\"</span><span class=\"nt\">&gt;</span>366.314<span class=\"nt\">&lt;/dust_ratio_to_fe_bioavail_frac_r&gt;</span>\n</code></pre></div>\n<p>I'm pretty sure I can change these via <code>user_nl_mom</code>, so I'll do that and re-run and see how things look</p>",
        "id": 46309,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636055693
    },
    {
        "content": "<p>Adding the following to <code>user_nl_mom</code>:</p>\n<div class=\"codehilite\"><pre><span></span><code>! G-compset default values\nDUST_RATIO_THRES = 69.00594\nDUST_RATIO_TO_FE_BIOAVAIL_FRAC = 2.729898e-3  ! 1 / 366.314\nFE_BIOAVAIL_FRAC_OFFSET = 0.0146756\n</code></pre></div>\n<p>seems to have made a huge difference. The 1-year MOM case is still running, but here are updated zonal means over the first 7 months [averaging POP over 7 months as well]:</p>\n<p><a href=\"/user_uploads/2/4d/DdDk7Bf9Q7d-6eG6RjqMUriB/Fe-zonal-mean-2.png\">Fe-zonal-mean-2.png</a> <br>\n<a href=\"/user_uploads/2/72/eenIZn0mzxnAX01hSkBfctOm/IRON_FLUX-zonal-mean-2.png\">IRON_FLUX-zonal-mean-2.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/4d/DdDk7Bf9Q7d-6eG6RjqMUriB/Fe-zonal-mean-2.png\" title=\"Fe-zonal-mean-2.png\"><img src=\"/user_uploads/2/4d/DdDk7Bf9Q7d-6eG6RjqMUriB/Fe-zonal-mean-2.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/2/72/eenIZn0mzxnAX01hSkBfctOm/IRON_FLUX-zonal-mean-2.png\" title=\"IRON_FLUX-zonal-mean-2.png\"><img src=\"/user_uploads/2/72/eenIZn0mzxnAX01hSkBfctOm/IRON_FLUX-zonal-mean-2.png\"></a></div><p>I'll update both the MOM and POP runs to add rivers back in and see how things look, and then a third round with sediment flux as well (assuming the rivers look good)</p>",
        "id": 46320,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636062831
    },
    {
        "content": "<p>That's a great improvement! Do you have a sense of what might explain the Arctic discrepancy?</p>",
        "id": 46323,
        "sender_full_name": "Matt Long",
        "timestamp": 1636063379
    },
    {
        "content": "<blockquote>\n<p>Do you have a sense of what might explain the Arctic discrepancy?</p>\n</blockquote>\n<p>A few theories, but I haven't had a chance to really investigate. This is just the top layer in the plots, so one thing I can do is make these plots for deeper layers... or even just look at the column-integrated iron instead of surface values. I'm definitely open to suggestions on where to look next :)</p>",
        "id": 46324,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636064022
    },
    {
        "content": "<p>I was wondering whether there is differing Fe treatment in ice—but these are C cases, right?</p>",
        "id": 46325,
        "sender_full_name": "Matt Long",
        "timestamp": 1636064074
    },
    {
        "content": "<p>the seasonality would't make sense either, as the SH went thru winter in the 7 mon integration</p>",
        "id": 46326,
        "sender_full_name": "Matt Long",
        "timestamp": 1636064106
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"14\">Matt Long</span> <a href=\"#narrow/stream/9-MOM6-dev/topic/MARBL.20driver.20for.20MOM6/near/46325\">said</a>:</p>\n<blockquote>\n<p>I was wondering whether there is differing Fe treatment in ice—but these are C cases, right?</p>\n</blockquote>\n<p>It could be ice - these are G cases (and one of the big differences between these runs is that POP is still using MCOG; I don't know if that's a possible explanation for iron differences but I could re-run the POP case with <code>lmcog = .false.</code> just to minimize differences between the runs)</p>",
        "id": 46330,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636120921
    },
    {
        "content": "<p>hmm... MCOG has the most substantial impact on spring productivity, which consumes Fe—so indeed, I'd expect that to generate diffs.  In coupled configurations, dust fluxes deposited on ice are retained, then subsequently released from the ice to the ocean. I can't remember how this works in G cases. You could consider looking directly at the respective coupler history files.</p>",
        "id": 46331,
        "sender_full_name": "Matt Long",
        "timestamp": 1636123368
    },
    {
        "content": "<p>I'm almost done with re-running POP without MCOG, but here's the Fe zonal mean comparison after 8 months:</p>\n<p><a href=\"/user_uploads/2/45/ZL4syvzu26VI9q5DJYVOoxJC/Fe-8-month-zonal-mean-no-mcog.png\">Fe-8-month-zonal-mean-no-mcog.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/45/ZL4syvzu26VI9q5DJYVOoxJC/Fe-8-month-zonal-mean-no-mcog.png\" title=\"Fe-8-month-zonal-mean-no-mcog.png\"><img src=\"/user_uploads/2/45/ZL4syvzu26VI9q5DJYVOoxJC/Fe-8-month-zonal-mean-no-mcog.png\"></a></div><p>That's definitely much closer than before, though there is still some separation between the two</p>",
        "id": 46332,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636125231
    },
    {
        "content": "<p>that does look better. Worth checking the forcing fields. Does the global integral of <code>IRON_FLUX</code> match?  Could put on a common grid to look at diffs: if the sea ice zone pops out, we'll know there's a problem there.</p>",
        "id": 46335,
        "sender_full_name": "Matt Long",
        "timestamp": 1636125946
    },
    {
        "content": "<p>For the global integrals, I multiplied <code>da*dz*area</code> (where <code>dz</code> was in units <code>m</code> and <code>area</code> in <code>m^2</code>), took the mean over <code>time</code>, and then summed over the remaining dimensions. I multiplied by <code>mmol_Fe_to_Tg = 55.845e-15 </code> for unit conversion; do</p>\n<div class=\"codehilite\"><pre><span></span><code>MOM global sum of Fe: 58.43 Tg\nPOP global sum of Fe: 59.76 Tg\n</code></pre></div>\n<p>seem like reasonable quantities or am I off by several orders of magnitude?  Assuming these are in the right ballpark, it's a 2-3% difference between them. I'll work on getting them to a common grid to look at the difference map</p>",
        "id": 46337,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636127174
    },
    {
        "content": "<p>A couple more variables of interest are the dust and black carbon fluxes coming in from CICE -- these are all in <code>g/cm^2/s</code> (I converted the MOM output from <code>kg/m^2/s</code>).</p>\n<p><a href=\"/user_uploads/2/70/T89aKiB9tLvy5jshLG8U7lXr/SEAICE_DUST_FLUX_CPL-zonal-mean.png\">SEAICE_DUST_FLUX_CPL-zonal-mean.png</a> <br>\n<a href=\"/user_uploads/2/36/6yI8GBqV7zust6MmgY3x6XP4/SEAICE_BLACK_CARBON_FLUX_CPL-zonal-mean.png\">SEAICE_BLACK_CARBON_FLUX_CPL-zonal-mean.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/70/T89aKiB9tLvy5jshLG8U7lXr/SEAICE_DUST_FLUX_CPL-zonal-mean.png\" title=\"SEAICE_DUST_FLUX_CPL-zonal-mean.png\"><img src=\"/user_uploads/2/70/T89aKiB9tLvy5jshLG8U7lXr/SEAICE_DUST_FLUX_CPL-zonal-mean.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/2/36/6yI8GBqV7zust6MmgY3x6XP4/SEAICE_BLACK_CARBON_FLUX_CPL-zonal-mean.png\" title=\"SEAICE_BLACK_CARBON_FLUX_CPL-zonal-mean.png\"><img src=\"/user_uploads/2/36/6yI8GBqV7zust6MmgY3x6XP4/SEAICE_BLACK_CARBON_FLUX_CPL-zonal-mean.png\"></a></div><p>Also, I just realized I computed global integral of <code>Fe</code>, not <code>IRON_FLUX</code>... I can get that in just a minute</p>",
        "id": 46338,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636128083
    },
    {
        "content": "<p>The iron fluxes are also a little different (intuitively these numbers look so small that I think I have to have messed up the unit conversion... but whatever I did wrong, I did wrong with both models)</p>\n<div class=\"codehilite\"><pre><span></span><code>MOM global sum of IRON_FLUX: 16.95 kg\nPOP global sum of IRON_FLUX: 17.06 kg\n</code></pre></div>",
        "id": 46339,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636128547
    },
    {
        "content": "<p>I would expect small differences as the grids are different. Those look close enough to me.</p>",
        "id": 46340,
        "sender_full_name": "Matt Long",
        "timestamp": 1636128635
    },
    {
        "content": "<p>The last thing I checked was ice fraction... interestingly enough, there are noticeable differences in the southern hemisphere but the northern hemisphere looks pretty close:</p>\n<p><a href=\"/user_uploads/2/4/exuSn-j_fwgFOsjgYaPhA7Rd/ECOSYS_IFRAC-zonal-mean.png\">ECOSYS_IFRAC-zonal-mean.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/4/exuSn-j_fwgFOsjgYaPhA7Rd/ECOSYS_IFRAC-zonal-mean.png\" title=\"ECOSYS_IFRAC-zonal-mean.png\"><img src=\"/user_uploads/2/4/exuSn-j_fwgFOsjgYaPhA7Rd/ECOSYS_IFRAC-zonal-mean.png\"></a></div><p>I'll continue with the plan of adding rivers back in, and making sure things still look close before putting the sediment flux back in as well</p>",
        "id": 46341,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636128725
    },
    {
        "content": "<p>difference in sea ice is not surprising—I think we saw substantial differences in Southern Ocean tracers indicating that the models have quite different representations of circulation in that region.</p>",
        "id": 46342,
        "sender_full_name": "Matt Long",
        "timestamp": 1636128799
    },
    {
        "content": "<p>Using <code>FESEDFLUX</code> forcings that I generated by mapping <code>sedfrac</code>, <code>POC</code>, <code>UVEL</code>, and <code>VVEL</code> directly to the MOM grid (rather than computing sediment flux on the POP grid and mapping to MOM after the fact), iron is looking much better! This is with river fluxes back in the run as well as the sediment flux, so basically out-of-the-box (I still need to figure out how to hard-code the right parameter set for the <code>GMOM</code> cases):</p>\n<p><a href=\"/user_uploads/2/c9/VfKcOjyQgX9TJU7rHXbaD1-0/yet-another-Fe-zonal-mean.png\">yet-another-Fe-zonal-mean.png</a> <br>\n<a href=\"/user_uploads/2/4b/_mVehrJ5pyfMUIFZDZ3z4gyk/zonal-mean-of-FESEDFLUX.png\">zonal-mean-of-FESEDFLUX.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/c9/VfKcOjyQgX9TJU7rHXbaD1-0/yet-another-Fe-zonal-mean.png\" title=\"yet-another-Fe-zonal-mean.png\"><img src=\"/user_uploads/2/c9/VfKcOjyQgX9TJU7rHXbaD1-0/yet-another-Fe-zonal-mean.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/2/4b/_mVehrJ5pyfMUIFZDZ3z4gyk/zonal-mean-of-FESEDFLUX.png\" title=\"zonal-mean-of-FESEDFLUX.png\"><img src=\"/user_uploads/2/4b/_mVehrJ5pyfMUIFZDZ3z4gyk/zonal-mean-of-FESEDFLUX.png\"></a></div><p>Alkalinity doesn't look so bad in this run, either -- this is just the average over the first year (and surface values), but I think in previous runs this looked far worse (in the year 16-20 average):</p>\n<p><a href=\"/user_uploads/2/c/Kyu1A2lmYkitZHKd1rCDNjsg/zonal-mean-of-ALK.png\">zonal-mean-of-ALK.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/c/Kyu1A2lmYkitZHKd1rCDNjsg/zonal-mean-of-ALK.png\" title=\"zonal-mean-of-ALK.png\"><img src=\"/user_uploads/2/c/Kyu1A2lmYkitZHKd1rCDNjsg/zonal-mean-of-ALK.png\"></a></div><p>Should I put together another 20 year run to see if (a) Fe really looks better, and (b) if Alkalinity diverges at some point?</p>",
        "id": 46630,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636555668
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> I looked back on my notes from the plots you shared on Oct 26 (at the ocean BGC group meeting), and I had written down</p>\n<blockquote>\n<p>ALK: big differences at 60 S in year 1 at surface! sizeable surface differences in year 20.</p>\n</blockquote>\n<p>I'm having trouble generating plots that show these differences, though - if the code to generate those plots are still available, could you share the year-1 alkalinity plot? I do notice a little separation between the two lines in my <code>zonal-mean-of-ALK.png</code>, so maybe it's something that is more obvious with a log scale for the <code>y</code> or even just a different range of <code>y</code> values?</p>\n<p>Also, <code>mom_oob.004</code> is running -- it has all the changes that led to the plots in my previous post. So far it's early in year 0003; I think it's on track to finish running sometime Friday? I'll be on PTO that day, but will compare to <code>pop_control</code> and <code>pop_no_mcog</code> on Monday.</p>",
        "id": 46791,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636585677
    },
    {
        "content": "<p>I saw the diff in year 1, but it was less in year 20. Here it is, zooming in on the southern hemisphere:<br>\n<a href=\"/user_uploads/2/c/QWZOZ_0G2gvaesm4Im9sfVFw/pop_mom.003_alk_surf_0001.png\">pop_mom.003_alk_surf_0001.png</a> <br>\nI'm now suspecting that this is from the sea ice initial condition.<br>\nI think the GMOM compset is starting off with uniform sea ice south of 60S.<br>\nWhen it melts, we're diluting ALK and DIC. I see a similar signal in DIC, though it is superimposed on the temperature dependent solubility.</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/c/QWZOZ_0G2gvaesm4Im9sfVFw/pop_mom.003_alk_surf_0001.png\" title=\"pop_mom.003_alk_surf_0001.png\"><img src=\"/user_uploads/2/c/QWZOZ_0G2gvaesm4Im9sfVFw/pop_mom.003_alk_surf_0001.png\"></a></div>",
        "id": 46831,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1636649283
    },
    {
        "content": "<p>that makes a lot of sense</p>",
        "id": 46833,
        "sender_full_name": "Matt Long",
        "timestamp": 1636650102
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span>! Zooming in, I do see a similar separation between roughly 65 S and 55 S in my plots. This sounds like something beyond the scope of fixes we can make, but I can chat with Dave B and see if there's a timeline for improving the initial state / anything easy we can do in the meantime. Maybe I could convert the ice state at year 20 from one of our runs to a new initial condition file? I assume that wouldn't be completely spun up to equilibrium, but it might be better than what we have now</p>",
        "id": 46835,
        "sender_full_name": "Michael Levy",
        "timestamp": 1636651679
    },
    {
        "content": "<p><code>mom_oob.004</code> has run for 20 years, and output is in <code>/glade/scratch/mlevy/archive/mom_oob.004/</code>. Looking at Fe output, there is a clear improvement over <code>mom_oob.003</code> but still some differences when compared with POP. Things look pretty good after a single year (these plots are all annual means):</p>\n<p><a href=\"/user_uploads/2/98/cmc9z6qsUYa_EYpm3L4B_VTn/fe-zonal-mean-0001-003-and-004.png\">fe-zonal-mean-0001-003-and-004.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/98/cmc9z6qsUYa_EYpm3L4B_VTn/fe-zonal-mean-0001-003-and-004.png\" title=\"fe-zonal-mean-0001-003-and-004.png\"><img src=\"/user_uploads/2/98/cmc9z6qsUYa_EYpm3L4B_VTn/fe-zonal-mean-0001-003-and-004.png\"></a></div><p>The average over five years show huge increases in iron in the arctic / subarctic for 003, but now a loss of iron there (relative to both the POP output and the year 1 output) for 004 (second plot is just the pop case and MOM 004 to get back to reasonable y-axis values):</p>\n<p><a href=\"/user_uploads/2/48/gIofgGUP3ybagIZ2pZZFJy1B/fe-zonal-mean-0005-003-and-004.png\">fe-zonal-mean-0005-003-and-004.png</a><br>\n<a href=\"/user_uploads/2/f0/En4lbnSdTXKqUqsok9wyu_rL/fe-zonal-mean-0005-004.png\">fe-zonal-mean-0005-004.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/48/gIofgGUP3ybagIZ2pZZFJy1B/fe-zonal-mean-0005-003-and-004.png\" title=\"fe-zonal-mean-0005-003-and-004.png\"><img src=\"/user_uploads/2/48/gIofgGUP3ybagIZ2pZZFJy1B/fe-zonal-mean-0005-003-and-004.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/2/f0/En4lbnSdTXKqUqsok9wyu_rL/fe-zonal-mean-0005-004.png\" title=\"fe-zonal-mean-0005-004.png\"><img src=\"/user_uploads/2/f0/En4lbnSdTXKqUqsok9wyu_rL/fe-zonal-mean-0005-004.png\"></a></div><p>None of the three runs show much difference between year 5 and year 20, but here is the 004 vs pop plot:</p>\n<p><a href=\"/user_uploads/2/92/JE8yN9ZqjFIYB_aDbR2K4VQ6/fe-zonal-mean-0020-004.png\">fe-zonal-mean-0020-004.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/92/JE8yN9ZqjFIYB_aDbR2K4VQ6/fe-zonal-mean-0020-004.png\" title=\"fe-zonal-mean-0020-004.png\"><img src=\"/user_uploads/2/92/JE8yN9ZqjFIYB_aDbR2K4VQ6/fe-zonal-mean-0020-004.png\"></a></div><p>From my notes, the changes made to 004 from 003 are</p>\n<blockquote>\n<p>Update RIV_FLUX file (previous file did not have proper unit conversion / time dimension)<br>\nFix vertical levels for POP history output (one level was still in cm instead of m)<br>\nBetter masking of values where ref_depth &gt;= bathyT<br>\nGet better PE layout OOB<br>\nDon't allocate memory for MARBL diags that MOM is not accumulating<br>\nBetter dust -&gt; iron parameters (I had hard-coded POP defaults for B / C compsets into MOM, but POP uses different values for G compsets)<br>\nUpdate FESEDFLUX files (map sedfrac, POC, UVEL, and VVEL to MOM grid and then compute sedflux rather than mapping sedflux from POP to MOM)</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> if you have a chance, can you poke around the 004 output ahead of the MARBL meeting tomorrow afternoon? I hope to discuss the iron differences some, and then also have time on the agenda to look at the rest of the output and see if anything else needs our attention. I think I mentioned this above, but output through year 20 is in <code>/glade/scratch/mlevy/archive/mom_oob.004/</code>.</p>",
        "id": 47037,
        "sender_full_name": "Michael Levy",
        "timestamp": 1637009134
    },
    {
        "content": "<p>I'll take a look at 004 before tomorrow's meeting.</p>",
        "id": 47048,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1637011976
    },
    {
        "content": "<blockquote>\n<p>I'll take a look at 004 before tomorrow's meeting.</p>\n</blockquote>\n<p>Thanks Keith!</p>",
        "id": 47059,
        "sender_full_name": "Michael Levy",
        "timestamp": 1637017571
    },
    {
        "content": "<p>A minor detail, but the plots I described as \"year 5\" <a href=\"#narrow/stream/9-MOM6-dev/topic/MARBL.20driver.20for.20MOM6/near/47037\">yesterday</a> are actually from year 6... I was using <code>range(60,72)</code> rather than <code>range(48,60)</code></p>",
        "id": 47092,
        "sender_full_name": "Michael Levy",
        "timestamp": 1637086922
    },
    {
        "content": "<p>A major detail is that they are a one-year average from year 6, not \"[t]he average over five years\" (I meant \"the average over year 0005\" when I thought that was the year I was averaging over; I get it closer to correct later in the post when I mention \"[n]one of the three runs show much difference between year 5 and year 20\")</p>",
        "id": 47093,
        "sender_full_name": "Michael Levy",
        "timestamp": 1637087043
    },
    {
        "content": "<p>Just as <span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> expected, changing the CICE initial condition (I used the restart written at the end of year 20 of <code>mom_oob.004</code>) had a huge effect on salinity and DIC in the first year:</p>\n<p><a href=\"/user_uploads/2/7/KzH72cBv2Cxk16dMmyH80k8E/salinity-zonal-mean-year-1.png\">salinity-zonal-mean-year-1.png</a> <br>\n<a href=\"/user_uploads/2/73/hFp6YA3A0zsFE3pUyF-tHyi6/DIC-zonal-mean-year-1.png\">DIC-zonal-mean-year-1.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/7/KzH72cBv2Cxk16dMmyH80k8E/salinity-zonal-mean-year-1.png\" title=\"salinity-zonal-mean-year-1.png\"><img src=\"/user_uploads/2/7/KzH72cBv2Cxk16dMmyH80k8E/salinity-zonal-mean-year-1.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/2/73/hFp6YA3A0zsFE3pUyF-tHyi6/DIC-zonal-mean-year-1.png\" title=\"DIC-zonal-mean-year-1.png\"><img src=\"/user_uploads/2/73/hFp6YA3A0zsFE3pUyF-tHyi6/DIC-zonal-mean-year-1.png\"></a></div><p>For the first plot, I didn't have <code>so</code> in the output stream of <code>mom_oob.004</code> so I couldn't include it in the comparison. For the second plot, the case named <code>mom_oob.004.single_year</code> is misnamed - that's <code>mom_oob.004</code> with better initial conditions (all three lines are from the first year).</p>\n<p>I think the only other big issue we discussed yesterday was getting the KPP mixing configured correctly (including nonlocal terms in passive tracers in MOM) - should we try to get a fix for that before starting the next 20 year run? There's also the minor issue of updating MARBL to put sinking particle fluxes on layer interfaces instead of the center.</p>\n<p>We discussed implementing a scaled salt flux to restore DIC and ALK, but it's not clear to me if that is necessary for the next 20 year run, or if that is something to consider if better ice initial conditions don't improve those two tracers.</p>",
        "id": 47172,
        "sender_full_name": "Michael Levy",
        "timestamp": 1637186031
    },
    {
        "content": "<p>In my opinion, we don't need to run a new experiment with every incremental update. I suggest that we spend more time examining this experiment and looking for issues to correct before starting a new experiment. So I propose working on including the KPP nonlocal term in passive tracers.</p>\n<p>Regarding the scaled salt fluxes, I think it separates into salt fluxes from the CICE model and salt fluxes from salinity restoring.</p>\n<p>On the 1st category of salt fluxes, I spoke <span class=\"user-mention\" data-user-id=\"115\">@Marika Holland</span> about including DIC and ALK tracers in the sea ice model. She thinks this definitely doable. It seems to us like it would be similar to the inclusion of nutrients in CICE, something that E3SM has experience with, while we don't have in-house experience with it. So this might take some time to implement. I'll try to chat w/ Elizabeth Hunke about this at lunch tomorrow. She is in Boulder for the CICE hackathon. The best person to chat with about this is probably Nicole Jeffery at LANL.</p>\n<p>I think we should proceed with adding scaled salt fluxes from salinity restoring to DIC and ALK surface fluxes.</p>\n<p>I suggest Mike and I meet to develop a roadmap for the KPP nonlocal term and scaled salt fluxes from salinity restoring.</p>",
        "id": 47175,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1637187867
    },
    {
        "content": "<p>Sounds great, <span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> !</p>",
        "id": 47191,
        "sender_full_name": "Matt Long",
        "timestamp": 1637190263
    },
    {
        "content": "<p>It does look like there's a unit issue in the river flux file that I'll try to sort out this afternoon or tomorrow:</p>\n<div class=\"codehilite\"><pre><span></span><code>Global integral of DON_RIV_FLUX from POP output: 9.461e+12 mmol/m^3 cm/s\nGlobal integral of don_riv_flux from POP forcing: 1.051e+13 nmol/cm^2/s\n----\nGlobal integral of DON_RIV_FLUX from MOM output: 9.464e+06 mmol/m^3 m/s\nGlobal integral of don_riv_flux from MOM forcing: 1.050e+07 mmol/m^2/s\n</code></pre></div>\n<p>For POP, even though the units in the output differs from that in the forcing file, <code>1 mmol / m^3 = 1 nmol / cm^3</code> so <code>1 mmol / m^3 cm/s = 1 nmol / cm^2 /s</code> (multiply both sides of the equation by <code>1 cm/s</code> and reduce). For MOM, I would expect values roughly O(<code>1e11 mmol / m^2 / s</code>) (taking the POP units, and converting the <code>cm/s</code> to <code>m/s</code>) so I think we are off by four orders of magnitude in the actual generation of the MOM forcing file.</p>",
        "id": 47972,
        "sender_full_name": "Michael Levy",
        "timestamp": 1638987915
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"10\">Michael Levy</span> <a href=\"#narrow/stream/9-MOM6-dev/topic/MARBL.20driver.20for.20MOM6/near/47972\">said</a>:</p>\n<blockquote>\n<p>It does look like there's a unit issue in the river flux file that I'll try to sort out this afternoon or tomorrow:</p>\n<div class=\"codehilite\"><pre><span></span><code>Global integral of DON_RIV_FLUX from POP output: 9.461e+12 mmol/m^3 cm/s\nGlobal integral of don_riv_flux from POP forcing: 1.051e+13 nmol/cm^2/s\n----\nGlobal integral of DON_RIV_FLUX from MOM output: 9.464e+06 mmol/m^3 m/s\nGlobal integral of don_riv_flux from MOM forcing: 1.050e+07 mmol/m^2/s\n</code></pre></div>\n<p>For POP, even though the units in the output differs from that in the forcing file, <code>1 mmol / m^3 = 1 nmol / cm^3</code> so <code>1 mmol / m^3 cm/s = 1 nmol / cm^2 /s</code> (multiply both sides of the equation by <code>1 cm/s</code> and reduce). For MOM, I would expect values roughly O(<code>1e11 mmol / m^2 / s</code>) (taking the POP units, and converting the <code>cm/s</code> to <code>m/s</code>) so I think we are off by four orders of magnitude in the actual generation of the MOM forcing file.</p>\n</blockquote>\n<p>I just realized this is incorrect -- the difference between the two is that I am integrating, so the POP units should be multiplied by <code>cm^2</code> (units of <code>TAREA</code>) while the MOM units should be multiplied by <code>m^2</code> (units of <code>area_t</code>). So I think everything actually matches up</p>",
        "id": 48000,
        "sender_full_name": "Michael Levy",
        "timestamp": 1638993637
    },
    {
        "content": "<p>I updated my MARBL driver sandbox to <code>cesm2_3_beta08</code>, got the NUOPC driver working (I think - at the very least, it is running without crashing), and then updated the MARBL driver to use the KPP nonlocal terms from <a href=\"https://github.com/NCAR/MOM6/pull/202\">NCAR/MOM6#202</a>. I ran into issues with the JRA repeated-year forcing, so I'm running with JRA interannual forcing.</p>\n<p>POP baseline is archived in <code>/glade/scratch/mlevy/archive/g.e23b08.TL319_g17.G1850POPECO_JRA.no_mcog</code> -- I ran for 24 years, though the MOM companion is only set up to run for 20... running POP in 6 year chunks let me spit out restart files every 3 years</p>\n<p>My first attempt at running the MOM case didn't provide output on the POP vertical grid and had the wrong default values for a few MARBL parameters (POP uses different defaults for G compsets than C/B for <code>DUST_RATIO_THRES</code>, <code>DUST_RATIO_TO_FE_BIOAVAIL_FRAC</code>, and <code>FE_BIOAVAIL_FRAC_OFFSET</code> but the updated values don't get added to <code>MOM_override</code> yet), so my second attempt is still running.</p>\n<p>The first 8 years are in <code>/glade/scratch/mlevy/archive/g.e23b08.TL319_t061.G1850MOMMARBL_JRA.002</code> and I'm seeing about 9.5 SYPD so I'm hoping to have 20 years by mid-afternoon tomorrow <span aria-label=\"fingers crossed\" class=\"emoji emoji-1f91e\" role=\"img\" title=\"fingers crossed\">:fingers_crossed:</span> </p>\n<p><span class=\"user-mention\" data-user-id=\"31\">@Keith Lindsay</span> and <span class=\"user-mention\" data-user-id=\"14\">@Matt Long</span> I'm hoping we can spend some time at our 3:30 meeting looking at the early output - I'm still noticing huge signatures from river runoff in fields like <code>ALK</code> and <code>DIC</code>, but that's expected / possibly the next issue to address? For example here's the Dec 0008 surface DIC on the same color bar (1150 -&gt; 4350 mmol / m^3; the MOM minimum is 300 mmol / m^3 but only in some coastal regions):</p>\n<p><a href=\"/user_uploads/2/2f/N3-cDoXriYid0tzwO8pR1XTQ/DIC-0008-12-MOM-vs-POP.png\">DIC-0008-12-MOM-vs-POP.png</a> </p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/2f/N3-cDoXriYid0tzwO8pR1XTQ/DIC-0008-12-MOM-vs-POP.png\" title=\"DIC-0008-12-MOM-vs-POP.png\"><img src=\"/user_uploads/2/2f/N3-cDoXriYid0tzwO8pR1XTQ/DIC-0008-12-MOM-vs-POP.png\"></a></div><p>By surface, I mean \"top level of POP output\" and \"top level of MOM output when writing diagnostics on the POP vertical levels\"... I can also provide \"top level of MOM output\" if that is a more meaningful comparison, but visually it's very similar to what is shown above</p>",
        "id": 53795,
        "sender_full_name": "Michael Levy",
        "timestamp": 1650383219
    },
    {
        "content": "<p>The 20-year MOM run finished... so there is now output for an updated MOM vs POP comparison</p>\n<ul>\n<li>POP (24 years): <code>/glade/scratch/mlevy/archive/g.e23b08.TL319_g17.G1850POPECO_JRA.no_mcog</code></li>\n<li>MOM (20 years): <code>/glade/scratch/mlevy/archive/g.e23b08.TL319_t061.G1850MOMMARBL_JRA.002</code></li>\n</ul>",
        "id": 54015,
        "sender_full_name": "Michael Levy",
        "timestamp": 1650598479
    },
    {
        "content": "<p>The diagnostic <code>DUST_FLUX_IN</code> is O(10) larger in MOM than in POP. I'm suspicious about the conversion of dust flux from kg/m^2/s to MARBL's CGS units. The MOM MARBL driver is multiplying by <code>kg_m2_s_conversion= kg_m2s_to_RZ_T</code>. I think this is just taking care of dimension scaling, but it doesn't take care of MKS-&gt;CGS. I think we need to also be multiplying by 0.1.</p>\n<p>I think the scaling of <code>IRON_FLUX</code> is correct.</p>\n<p>The impact on <code>Fe</code> is complicated. Increased dust flux enhances scavenging, which I see in the output. However, the remineralization of dust also adds Fe to the system.</p>\n<p><code>POC_FLUX_100m</code> is similar in MOM and POP, but <code>pocToSed</code> is about 46% larger in MOM than in POP, in year 1. This might be because of an increase in ballasting from excessive dust.</p>\n<p>MARBL generates a surface flux of <code>PO4</code> and <code>SiO3</code> from dust flux. So those are increased.</p>",
        "id": 54050,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1650670906
    },
    {
        "content": "<p>MARBL-MOM6 expr 006, through year 4, looks improved compared to 005. Here are maps of Arctic Fe over the top 10m in 004, 005, 006, and POP, all with MCOG:<br>\n<a href=\"/user_uploads/2/1d/P13vVeBElrNLDb3VOIS2R_WE/image.png\">image.png</a><br>\nGlobal sinking Fe flux at 100m is now lower in 006 than POP, while previous MOM experiment were higher than in POP.<br>\n<a href=\"/user_uploads/2/ed/XSvnme2grq4nvyoWiqsTCfoD/image.png\">image.png</a><br>\nI'll need to dig in more.</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/2/1d/P13vVeBElrNLDb3VOIS2R_WE/image.png\" title=\"image.png\"><img src=\"/user_uploads/2/1d/P13vVeBElrNLDb3VOIS2R_WE/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/2/ed/XSvnme2grq4nvyoWiqsTCfoD/image.png\" title=\"image.png\"><img src=\"/user_uploads/2/ed/XSvnme2grq4nvyoWiqsTCfoD/image.png\"></a></div>",
        "id": 68132,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1667930706
    },
    {
        "content": "<p>The left column is tracer concentration. The right column is tracer concentration normalized to salinity=35.</p>",
        "id": 68140,
        "sender_full_name": "Keith Lindsay",
        "timestamp": 1667932040
    }
]