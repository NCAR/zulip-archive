[
    {
        "content": "<p>I realize this isn't exactly a common scientific computing question, but I figured given the depth of Python experience here, maybe people have ideas.  I'm trying to do a simple HTTP 'POST' operation to a public IP address of a REST API, and I'm interested in doing it in an asynchronous fashion so that when I'm on a compute node (or more generally behind a firewall), and it can't actually reach the IP, it doesn't pause for whatever the timeout duration is.  I don't even need a return code, I'm just trying to find a better approach than a 'try/except' loop on a timeout.  Any leads or ideas?</p>",
        "id": 60026,
        "sender_full_name": "Brian Dobbins",
        "timestamp": 1658897346
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"65\">@Brian Dobbins</span>,  if you haven't done so already, take a look at the <code>backoff</code> package: <a href=\"https://pypi.org/project/backoff/\">https://pypi.org/project/backoff/</a>. This package provides a decorator that you may use to control the retry logic. For asynchronous calls, you will need an addition package: <code>aiohttp</code>: <a href=\"https://docs.aiohttp.org/en/stable/\">https://docs.aiohttp.org/en/stable/</a> </p>\n<div class=\"codehilite\" data-code-language=\"Python\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"nn\">aiohttp</span>\n<span class=\"kn\">import</span> <span class=\"nn\">backoff</span>\n\n<span class=\"nd\">@backoff</span><span class=\"o\">.</span><span class=\"n\">on_exception</span><span class=\"p\">(</span><span class=\"n\">backoff</span><span class=\"o\">.</span><span class=\"n\">expo</span><span class=\"p\">,</span> <span class=\"n\">aiohttp</span><span class=\"o\">.</span><span class=\"n\">ClientError</span><span class=\"p\">,</span> <span class=\"n\">max_time</span><span class=\"o\">=</span><span class=\"mi\">60</span><span class=\"p\">)</span>\n<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">post_to_url</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">):</span>\n    <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">aiohttp</span><span class=\"o\">.</span><span class=\"n\">ClientSession</span><span class=\"p\">(</span><span class=\"n\">raise_for_status</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">session</span><span class=\"p\">:</span>\n        <span class=\"k\">async</span> <span class=\"k\">with</span> <span class=\"n\">session</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span><span class=\"n\">url</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">response</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"k\">await</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">text</span><span class=\"p\">()</span>\n</code></pre></div>",
        "id": 60039,
        "sender_full_name": "Anderson Banihirwe",
        "timestamp": 1658937156
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"13\">@Anderson Banihirwe</span> Thanks very, very much for your help, Anderson.   I'm still a very novice Python coder, so bear with me on a simple follow-up question?  It seems to use the async I/O options, I need a fully async main loop, which complicates some of the <em>synchronous</em> logic I want.  Another option I just tried, which seems to work, uses Python's 'multiprocessing' package to launch a second process that does the POST operation, and terminates that process when the primary logic ends, eg:</p>\n<div class=\"codehilite\"><pre><span></span><code>p = multiprocessing.Process(target=post_function, args=(url, body))\n...\np.terminate() # Later on - if the post worked, great.  If not, we don&#39;t care, so terminate.\n</code></pre></div>\n<p>Does this approach seem reasonable, too, or are there downsides to it that I'm missing in my inexperience?  We don't care to retry the POST; if it works, great.  If not, no big deal.  So terminating the process is fine.  The REST endpoint ensures we don't get corrupt / partial data from an interrupted transfer, too.</p>\n<p>Thanks again - I owe you a drink or lunch sometime.  :-)</p>",
        "id": 60058,
        "sender_full_name": "Brian Dobbins",
        "timestamp": 1658945109
    },
    {
        "content": "<blockquote>\n<p>Does this approach seem reasonable, too, or are there downsides to it that I'm missing in my inexperience?  </p>\n</blockquote>\n<p>without seeing the rest of your code, I think the <code>multiprocessing.Process(....)</code> approach is reasonable.  Supporting <code>async IO</code> throughout your codebase may come at the cost of having to rewrite most of your code -- which is perhaps not worth the price.</p>",
        "id": 60135,
        "sender_full_name": "Anderson Banihirwe",
        "timestamp": 1658958011
    },
    {
        "content": "<p>I'm curious... When the HTTP POST is synchronous, does it result in a significant performance penalty?  I would love to see what you are building with this <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>. It sounds interesting.... </p>\n<blockquote>\n<p>Thanks again - I owe you a drink or lunch sometime. :-)</p>\n</blockquote>\n<p>I'm game whenever  <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 60137,
        "sender_full_name": "Anderson Banihirwe",
        "timestamp": 1658958503
    },
    {
        "content": "<p>Thanks again, and I'll ping you in a week or so about lunch or drinks.  It'd be fantastic to catch up!</p>\n<p>As for the code, it's part of a dataset tool, with this bit enabling some very basic metrics -- what dataset is someone trying to access, and from where (their IP).  The idea is that with that information, we can not only try to replicate data in areas of high use, but also do it in a way transparent to the user so that notebooks are fully portable while using the closest / fastest copy.  The POST operation is to send those two data points to a REST API (that in turn, writes it to a database), and the reason I don't want it synchronous is that if you're on a system without routing to the internet -like, say, a Cheyenne compute node?- it's really annoying to have a near-instantaneous operation hang for 60+ seconds!  But there's also no trivial way to know if you can route to the internet, so we try, and don't worry about it if we fail.  After all, we allow it to be disabled too.</p>\n<p>I'll share the code (it'll be on Github, really), but since recording an IP is potentially 'user information', we have to chat with the Office of General Counsel to see if it's fine as-is or needs changes before we make the package public.</p>",
        "id": 60155,
        "sender_full_name": "Brian Dobbins",
        "timestamp": 1658971703
    },
    {
        "content": "<p>Hi, just saw this \"quick timeout\" check that might also avoid a long timeout response:</p>\n<p><a href=\"https://stackoverflow.com/questions/3764291/how-can-i-see-if-theres-an-available-and-active-network-connection-in-python\">https://stackoverflow.com/questions/3764291/how-can-i-see-if-theres-an-available-and-active-network-connection-in-python</a></p>",
        "id": 60156,
        "sender_full_name": "Brian Bonnlander",
        "timestamp": 1658972293
    },
    {
        "content": "<p>Ah, but I'm seeing this may no longer work...anyway, I have heard of \"fail fast\" ways to check if a connection is available.   It's a common use case for applications that rely on network services.</p>",
        "id": 60157,
        "sender_full_name": "Brian Bonnlander",
        "timestamp": 1658972464
    },
    {
        "content": "<p>Interesting, thanks, Brian - lots of ideas in here, some of which I need to understand better.  I think they tend to be focused more on multi-second timeout checks of connectivity, which typically can 'fail fast' in scenarios where links are <em>down</em>, but the firewalled compute nodes are a different beast, since pockets are literally dropped.  So in each of the cases I've tried, it still just falls back to the timeout.  Normally a few seconds should be more than sufficient too, with cached responses taking mere fractions of a second,  but I think an asynchronous approach is even better since it's effectively no time at all.</p>\n<p>Anyway, I have lots more to play with now, so thanks again!</p>",
        "id": 60159,
        "sender_full_name": "Brian Dobbins",
        "timestamp": 1658981729
    }
]