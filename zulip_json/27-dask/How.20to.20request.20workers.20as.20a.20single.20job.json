[
    {
        "content": "<p>I am trying to spin up a dask cluster with 72 workers, and when the machine gets busy it can take a lot of time for all the workers to be ready at once... so several workers may sit idle for a while (and, in extreme cases, the first workers to get launched may run out of walltime before the rest of the cluster is available).</p>\n<p>I'm currently running</p>\n<div class=\"codehilite\" data-code-language=\"Python\"><pre><span></span><code><span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">PBSCluster</span><span class=\"p\">(</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"s1\">'20 GB'</span><span class=\"p\">,</span>\n    <span class=\"n\">processes</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">cores</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"n\">queue</span><span class=\"o\">=</span><span class=\"s1\">'casper'</span><span class=\"p\">,</span>\n    <span class=\"n\">walltime</span><span class=\"o\">=</span><span class=\"s1\">'1:30:00'</span><span class=\"p\">,</span>\n    <span class=\"n\">resource_spec</span><span class=\"o\">=</span><span class=\"s1\">'select=1:ncpus=1:mem=20GB'</span><span class=\"p\">,</span>\n    <span class=\"n\">log_directory</span><span class=\"o\">=</span><span class=\"s1\">'./dask-logs'</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">scale</span><span class=\"p\">(</span><span class=\"mi\">72</span><span class=\"p\">)</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"p\">)</span>\n<span class=\"n\">client</span>\n</code></pre></div>\n<p>so I get 72 jobs, each requesting a single core and being treated as a single worker. Is there a way to have <code>cluster.scale()</code> submit a single job request? If I were to blindly change things, I would try</p>\n<div class=\"codehilite\" data-code-language=\"Python\"><pre><span></span><code><span class=\"n\">cluster</span> <span class=\"o\">=</span> <span class=\"n\">PBSCluster</span><span class=\"p\">(</span>\n    <span class=\"n\">memory</span><span class=\"o\">=</span><span class=\"s1\">'1440 GB'</span><span class=\"p\">,</span>\n    <span class=\"n\">processes</span><span class=\"o\">=</span><span class=\"mi\">72</span><span class=\"p\">,</span>\n    <span class=\"n\">cores</span><span class=\"o\">=</span><span class=\"mi\">72</span><span class=\"p\">,</span>\n    <span class=\"n\">queue</span><span class=\"o\">=</span><span class=\"s1\">'casper'</span><span class=\"p\">,</span>\n    <span class=\"n\">walltime</span><span class=\"o\">=</span><span class=\"s1\">'1:30:00'</span><span class=\"p\">,</span>\n    <span class=\"n\">resource_spec</span><span class=\"o\">=</span><span class=\"s1\">'select=72:ncpus=1:mem=20GB'</span><span class=\"p\">,</span>\n    <span class=\"n\">log_directory</span><span class=\"o\">=</span><span class=\"s1\">'./dask-logs'</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"n\">cluster</span><span class=\"o\">.</span><span class=\"n\">scale</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"n\">client</span> <span class=\"o\">=</span> <span class=\"n\">Client</span><span class=\"p\">(</span><span class=\"n\">cluster</span><span class=\"p\">)</span>\n<span class=\"n\">client</span>\n</code></pre></div>\n<p>but I'm pretty confused about the interaction between dask and PB. I want to avoid a situation where I request 72 cores and dask treats that as a single worker.</p>",
        "id": 81779,
        "sender_full_name": "Michael Levy",
        "timestamp": 1685469910
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"10\">@Michael Levy</span> Have you seen <a href=\"https://github.com/NCAR/dask-tutorial/blob/main/notebooks/05-dask-hpc.ipynb\">this notebook</a> from the dask tutorial led by <span class=\"user-mention\" data-user-id=\"71\">@Negin Sobhani</span> and <span class=\"user-mention\" data-user-id=\"141\">@Brian Vanderwende</span> this past spring? I found it to be a very helpful resource for understanding PBS and dask. I'm not sure if it answers your exact question though. Maybe tweaking the <code>resource_spec</code> relative to the <code>cores</code>parameter? Could <a href=\"https://docs.dask.org/en/stable/how-to/adaptive.html\">adaptive scaling</a> be useful here?</p>",
        "id": 81798,
        "sender_full_name": "Katie Dagon",
        "timestamp": 1685475752
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"47\">@Katie Dagon</span> ! I hadn't seen that notebook, but I'll read through it and follow some of the links. I think my use-case is different from most, though, so I'd like to stay away from adaptive scaling. While typical scripts can start running with a few workers and then scale up, I'd really like to make sure we have all the memory / cores we requested before doing any computation - and if we're going to wait for all of the workers to be available, it makes sense to let PBS treat it as a single job request instead of running one worker at a time as the resources become available.</p>",
        "id": 81799,
        "sender_full_name": "Michael Levy",
        "timestamp": 1685476091
    }
]